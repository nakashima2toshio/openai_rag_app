# a30_01_rag.py - OpenAI Agent SDKç‰ˆ
# a30_01_rag.py - OpenAI Agent SDK/Responses APIç‰ˆ
import streamlit as st
import time
import logging
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime
from pathlib import Path
import json
import traceback

# OpenAI Agent SDK ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from openai import OpenAI
    from openai_agents import Agent, Runner, Session, FileSearchTool
    from openai_agents.tools import function_tool
    from openai_agents.streaming import StreamingRunner

    AGENT_SDK_AVAILABLE = True
except ImportError:
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å¾“æ¥ã®OpenAI API
    from openai import OpenAI

    AGENT_SDK_AVAILABLE = False
    st.warning(
        "OpenAI Agent SDK ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å¾“æ¥ã®APIä½¿ç”¨ã—ã¾ã™ã€‚`pip install openai-agents` ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ã€‚")

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Vector Store IDã®è¨­å®š
VECTOR_STORES = {
    "Customer Support FAQ"    : "vs_687a0604f1508191aaf416d88e266ab7",
    "Science & Technology Q&A": "vs_687a061acc908191af7d5d9ba623470b",
    "Medical Q&A"             : "vs_687a060f9ed881918b213bfdeab8241b",
    "Legal Q&A"               : "vs_687a062418ec8191872efdbf8f554836"
}

# OpenAI APIã‚­ãƒ¼ã®è¨­å®š
try:
    openai_client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])
except Exception as e:
    st.error(f"OpenAI API ã‚­ãƒ¼ã®è¨­å®šã«å•é¡ŒãŒã‚ã‚Šã¾ã™: {e}")
    st.stop()


class RAGAgentManager:
    """RAGã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ç®¡ç†ã‚¯ãƒ©ã‚¹"""

    def __init__(self):
        self.agents = {}
        self.sessions = {}
        self.initialize_agents()

    def initialize_agents(self):
        """å„Vector Storeç”¨ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’åˆæœŸåŒ–"""
        for store_name, store_id in VECTOR_STORES.items():
            if AGENT_SDK_AVAILABLE:
                self.agents[store_name] = self.create_agent_sdk_rag(store_name, store_id)
            else:
                self.agents[store_name] = self.create_fallback_rag(store_name, store_id)

    def create_agent_sdk_rag(self, store_name: str, store_id: str) -> Agent:
        """Agent SDKã‚’ä½¿ç”¨ã—ãŸRAGã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ä½œæˆ"""
        instructions = f"""
        ã‚ãªãŸã¯{store_name}ã®å°‚é–€æ¤œç´¢ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
        ä»¥ä¸‹ã®å½¹å‰²ã‚’æœãŸã—ã¦ãã ã•ã„ï¼š

        1. è³ªå•ã«å¯¾ã—ã¦é–¢é€£ã™ã‚‹æƒ…å ±ã‚’æ¤œç´¢ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã£ã¦èª¿ã¹ã‚‹
        2. æ¤œç´¢çµæœã‚’åŸºã«ã€æ­£ç¢ºã§æœ‰ç”¨ãªå›ç­”ã‚’æ—¥æœ¬èªã§æä¾›ã™ã‚‹
        3. æƒ…å ±æºãŒã‚ã‚‹å ´åˆã¯é©åˆ‡ã«å¼•ç”¨ã™ã‚‹
        4. æ¤œç´¢çµæœãŒãªã„å ´åˆã¯ã€ãã®æ—¨ã‚’æ˜ç¢ºã«ä¼ãˆã‚‹
        5. æ›–æ˜§ãªè³ªå•ã«ã¯æ˜ç¢ºåŒ–ã‚’æ±‚ã‚ã‚‹

        å¸¸ã«è¦ªåˆ‡ã§å°‚é–€çš„ãªå¯¾å¿œã‚’å¿ƒãŒã‘ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«æœ€é©ãªç­”ãˆã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚
        """

        agent = Agent(
            name=f"RAG_{store_name.replace(' ', '_')}",
            instructions=instructions,
            tools=[FileSearchTool(vector_store_ids=[store_id])],
            model="gpt-4o-mini"
        )
        return agent

    def create_fallback_rag(self, store_name: str, store_id: str) -> Dict:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®å¾“æ¥å‹RAGè¨­å®š"""
        return {
            "name"        : store_name,
            "store_id"    : store_id,
            "instructions": f"ã‚ãªãŸã¯{store_name}ã®å°‚é–€æ¤œç´¢ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"
        }

    def get_or_create_session(self, store_name: str, user_id: str = "default") -> Optional[Session]:
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®å–å¾—ã¾ãŸã¯ä½œæˆ"""
        if not AGENT_SDK_AVAILABLE:
            return None

        session_key = f"{store_name}_{user_id}"
        if session_key not in self.sessions:
            self.sessions[session_key] = Session(session_key)
        return self.sessions[session_key]

    def search_with_agent_sdk(self, query: str, store_name: str) -> Tuple[str, Dict]:
        """Agent SDKã‚’ä½¿ç”¨ã—ãŸæ¤œç´¢"""
        try:
            agent = self.agents[store_name]
            session = self.get_or_create_session(store_name)

            # æ¤œç´¢å®Ÿè¡Œ
            result = Runner.run_sync(agent, query, session=session)

            response_text = result.final_output if hasattr(result, 'final_output') else str(result)

            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®åé›†
            metadata = {
                "store_name": store_name,
                "query"     : query,
                "timestamp" : datetime.now().isoformat(),
                "model"     : "gpt-4o-mini",
                "method"    : "agent_sdk"
            }

            # å®Ÿè¡Œçµ±è¨ˆãŒã‚ã‚Œã°è¿½åŠ 
            if hasattr(result, 'usage'):
                metadata["usage"] = result.usage

            return response_text, metadata

        except Exception as e:
            error_msg = f"Agent SDKæ¤œç´¢ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
            logger.error(error_msg)
            logger.error(traceback.format_exc())
            return error_msg, {"error": str(e), "method": "agent_sdk"}

    def search_with_fallback(self, query: str, store_name: str) -> Tuple[str, Dict]:
        """Responses APIã‚’ä½¿ã£ãŸãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ¤œç´¢"""
        try:
            agent_config = self.agents[store_name]
            store_id = agent_config["store_id"]
            # æœ€æ–°Responses API ã§ã‚·ãƒ³ãƒ—ãƒ«ã«RAG
            resp = openai_client.responses.create(
                model="gpt-4o-mini",
                tools=[FileSearchTool(vector_store_ids=[store_id])],
                # tools=[{"type": "file_search", "vector_store_ids": [store_id]}],
                input=query
            )
            # output_text ã®å–å¾—ã€‚å¿œç­”å†…å®¹ãŒ output_text ã«æ ¼ç´ã•ã‚Œã‚‹
            response_text = resp.output_text

            metadata = {
                "store_name": store_name,
                "query"     : query,
                "timestamp" : datetime.now().isoformat(),
                "model"     : "gpt-4o-mini",
                "method"    : "responses_api"
            }

            return response_text, metadata

        except Exception as e:
            error_msg = f"æ¤œç´¢ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
            logger.error(error_msg)
            logger.error(traceback.format_exc())
            return error_msg, {"error": str(e), "method": "responses_api"}

    def search(self, query: str, store_name: str) -> Tuple[str, Dict]:
        """çµ±åˆæ¤œç´¢ãƒ¡ã‚½ãƒƒãƒ‰"""
        if AGENT_SDK_AVAILABLE:
            return self.search_with_agent_sdk(query, store_name)
        else:
            return self.search_with_fallback(query, store_name)

    def stream_search(self, query: str, store_name: str):
        """ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°æ¤œç´¢ï¼ˆAgent SDKåˆ©ç”¨æ™‚ã®ã¿ï¼‰"""
        if not AGENT_SDK_AVAILABLE:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¨ã—ã¦é€šå¸¸æ¤œç´¢
            result, metadata = self.search(query, store_name)
            yield result, metadata
            return

        try:
            agent = self.agents[store_name]
            session = self.get_or_create_session(store_name)

            # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å®Ÿè¡Œ
            streaming_runner = StreamingRunner()

            for chunk in streaming_runner.run_stream(agent, query, session=session):
                if hasattr(chunk, 'content'):
                    yield chunk.content, {"streaming": True}
                elif hasattr(chunk, 'delta'):
                    yield chunk.delta, {"streaming": True}
                else:
                    yield str(chunk), {"streaming": True}

        except Exception as e:
            error_msg = f"ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°æ¤œç´¢ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
            logger.error(error_msg)
            yield error_msg, {"error": str(e), "method": "stream"}


# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
@st.cache_resource
def get_rag_manager():
    """RAGã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³å–å¾—"""
    return RAGAgentManager()


def initialize_session_state():
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–"""
    if 'search_history' not in st.session_state:
        st.session_state.search_history = []
    if 'current_query' not in st.session_state:
        st.session_state.current_query = ""
    if 'selected_store' not in st.session_state:
        st.session_state.selected_store = list(VECTOR_STORES.keys())[0]
    if 'streaming_enabled' not in st.session_state:
        st.session_state.streaming_enabled = AGENT_SDK_AVAILABLE


def display_search_history():
    """æ¤œç´¢å±¥æ­´ã®è¡¨ç¤º"""
    st.header("ğŸ•’ æ¤œç´¢å±¥æ­´")

    if not st.session_state.search_history:
        st.info("æ¤œç´¢å±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“")
        return

    # å±¥æ­´ã‚’ã‚¿ãƒ–ã§è¡¨ç¤º
    for i, item in enumerate(st.session_state.search_history[:10]):  # æœ€æ–°10ä»¶
        with st.expander(f"å±¥æ­´ {i + 1}: {item['query'][:50]}..."):
            st.markdown(f"**è³ªå•:** {item['query']}")
            st.markdown(f"**Vector Store:** {item['store_name']}")
            st.markdown(f"**å®Ÿè¡Œæ™‚é–“:** {item['timestamp']}")
            st.markdown(f"**æ¤œç´¢æ–¹æ³•:** {item.get('method', 'unknown')}")

            if st.button("å†å®Ÿè¡Œ", key=f"rerun_{i}"):
                st.session_state.current_query = item['query']
                st.session_state.selected_store = item['store_name']
                st.rerun()


def display_test_questions():
    """ãƒ†ã‚¹ãƒˆç”¨è³ªå•ã®è¡¨ç¤º"""
    st.header("ğŸ’¡ ãƒ†ã‚¹ãƒˆç”¨è³ªå•")

    test_questions = {
        "Customer Support FAQ"    : [
            "æ–°è¦ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’ä½œã‚‹ã«ã¯ã©ã†ã™ã‚Œã°ã‚ˆã„ã§ã™ã‹ï¼Ÿ",
            "ã©ã®ã‚ˆã†ãªæ±ºæ¸ˆæ–¹æ³•ãŒåˆ©ç”¨ã§ãã¾ã™ã‹ï¼Ÿ",
            "å•†å“ã‚’è¿”å“ã™ã‚‹ã“ã¨ã¯ã§ãã¾ã™ã‹ï¼Ÿ",
            "ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å¿˜ã‚Œã¦ã—ã¾ã„ã¾ã—ãŸ",
            "ã‚µãƒãƒ¼ãƒˆãƒãƒ¼ãƒ ã«é€£çµ¡ã™ã‚‹æ–¹æ³•ã‚’æ•™ãˆã¦ãã ã•ã„"
        ],
        "Science & Technology Q&A": [
            "äººå·¥çŸ¥èƒ½ã®æœ€æ–°å‹•å‘ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„",
            "é‡å­ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã®åŸç†ã¨ã¯ï¼Ÿ",
            "å†ç”Ÿå¯èƒ½ã‚¨ãƒãƒ«ã‚®ãƒ¼ã®ç¨®é¡ã¨ç‰¹å¾´",
            "éºä¼å­ç·¨é›†æŠ€è¡“ã®ç¾çŠ¶ã¨èª²é¡Œ",
            "å®‡å®™æ¢æŸ»ã®æœ€æ–°æŠ€è¡“ã«ã¤ã„ã¦"
        ],
        "Medical Q&A"             : [
            "é«˜è¡€åœ§ã®äºˆé˜²æ–¹æ³•ã«ã¤ã„ã¦",
            "ç³–å°¿ç—…ã®ç—‡çŠ¶ã¨æ²»ç™‚æ³•",
            "å¿ƒè‡“ç—…ã®ãƒªã‚¹ã‚¯ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼",
            "å¥åº·çš„ãªé£Ÿäº‹ã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³",
            "é‹å‹•ã¨å¥åº·ã®é–¢ä¿‚ã«ã¤ã„ã¦"
        ],
        "Legal Q&A"               : [
            "å¥‘ç´„æ›¸ã®é‡è¦ãªæ¡é …ã«ã¤ã„ã¦",
            "çŸ¥çš„è²¡ç”£æ¨©ã®ä¿è­·æ–¹æ³•",
            "åŠ´åƒæ³•ã®åŸºæœ¬åŸå‰‡",
            "å€‹äººæƒ…å ±ä¿è­·æ³•ã®æ¦‚è¦",
            "æ¶ˆè²»è€…ä¿è­·æ³•ã®é©ç”¨ç¯„å›²"
        ]
    }

    selected_category = st.selectbox(
        "ã‚«ãƒ†ã‚´ãƒªã‚’é¸æŠ",
        list(test_questions.keys()),
        key="test_category"
    )

    questions = test_questions[selected_category]

    for i, question in enumerate(questions):
        if st.button(f"è³ªå• {i + 1}: {question}", key=f"test_q_{selected_category}_{i}"):
            st.session_state.current_query = question
            st.session_state.selected_store = selected_category
            st.rerun()


def display_system_info():
    """ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±ã®è¡¨ç¤º"""
    with st.expander("ğŸ”§ ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±", expanded=False):
        st.write("**åˆ©ç”¨å¯èƒ½ãªæ©Ÿèƒ½:**")
        st.write(f"- OpenAI Agent SDK: {'âœ…' if AGENT_SDK_AVAILABLE else 'âŒ'}")
        st.write(f"- ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°æ¤œç´¢: {'âœ…' if AGENT_SDK_AVAILABLE else 'âŒ'}")
        st.write(f"- ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†: {'âœ…' if AGENT_SDK_AVAILABLE else 'âŒ'}")

        st.write("**Vector Stores:**")
        for name, store_id in VECTOR_STORES.items():
            st.write(f"- {name}: `{store_id}`")

        if st.session_state.search_history:
            st.write(f"**æ¤œç´¢å±¥æ­´:** {len(st.session_state.search_history)} ä»¶")


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    st.set_page_config(
        page_title="RAGæ¤œç´¢ãƒ†ã‚¹ãƒˆã‚¢ãƒ—ãƒªï¼ˆAgent SDKç‰ˆï¼‰",
        page_icon="ğŸ”",
        layout="wide"
    )

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
    initialize_session_state()

    # RAGãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®å–å¾—
    rag_manager = get_rag_manager()

    # ãƒ˜ãƒƒãƒ€ãƒ¼
    st.title("ğŸ” RAGæ¤œç´¢ãƒ†ã‚¹ãƒˆã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆAgent SDKç‰ˆï¼‰")

    if AGENT_SDK_AVAILABLE:
        st.success("âœ… OpenAI Agent SDK ãŒåˆ©ç”¨å¯èƒ½ã§ã™")
    else:
        st.warning("âš ï¸ OpenAI Agent SDK ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚å¾“æ¥ã®API ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")

    st.markdown("---")

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    with st.sidebar:
        st.header("âš™ï¸ è¨­å®š")

        # Vector Storeé¸æŠ
        selected_store = st.selectbox(
            "Vector Store ã‚’é¸æŠ",
            options=list(VECTOR_STORES.keys()),
            index=list(VECTOR_STORES.keys()).index(st.session_state.selected_store),
            key="store_selection"
        )
        st.session_state.selected_store = selected_store

        # é¸æŠã•ã‚ŒãŸVector Store IDã‚’è¡¨ç¤º
        st.code(VECTOR_STORES[selected_store])

        # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è¨­å®š
        if AGENT_SDK_AVAILABLE:
            streaming_enabled = st.checkbox(
                "ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°æ¤œç´¢ã‚’æœ‰åŠ¹ã«ã™ã‚‹",
                value=st.session_state.streaming_enabled,
                help="ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§å¿œç­”ã‚’è¡¨ç¤ºã—ã¾ã™"
            )
            st.session_state.streaming_enabled = streaming_enabled

        # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±
        display_system_info()

        # ãƒ†ã‚¹ãƒˆç”¨è³ªå•
        with st.expander("ğŸ’¡ ãƒ†ã‚¹ãƒˆç”¨è³ªå•", expanded=True):
            display_test_questions()

    # ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
    col1, col2 = st.columns([1, 1])

    with col1:
        st.header("â“ è³ªå•å…¥åŠ›")

        # è³ªå•å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ 
        with st.form("search_form"):
            query = st.text_area(
                "è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
                value=st.session_state.current_query,
                height=100,
                key="query_input"
            )

            submitted = st.form_submit_button("ğŸ” æ¤œç´¢å®Ÿè¡Œ", type="primary")

        if submitted and query.strip():
            st.session_state.current_query = query

            # æ¤œç´¢å®Ÿè¡Œ
            with col2:
                st.header("ğŸ¤– æ¤œç´¢çµæœ")

                if st.session_state.streaming_enabled and AGENT_SDK_AVAILABLE:
                    # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°æ¤œç´¢
                    result_container = st.empty()
                    accumulated_result = ""

                    with st.spinner("æ¤œç´¢ä¸­..."):
                        for chunk, metadata in rag_manager.stream_search(query, selected_store):
                            if isinstance(chunk, str):
                                accumulated_result += chunk
                                result_container.markdown(accumulated_result)
                            time.sleep(0.1)  # è¡¨ç¤ºã®èª¿æ•´

                    final_result = accumulated_result
                    final_metadata = metadata

                else:
                    # é€šå¸¸æ¤œç´¢
                    with st.spinner("æ¤œç´¢ä¸­..."):
                        final_result, final_metadata = rag_manager.search(query, selected_store)

                    st.markdown("### ğŸ¤– å›ç­”")
                    st.markdown(final_result)

                # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è¡¨ç¤º
                st.markdown("---")
                st.markdown("### ğŸ“Š æ¤œç´¢æƒ…å ±")
                st.markdown(f"**ä½¿ç”¨ã—ãŸVector Store:** {selected_store}")
                st.markdown(f"**Vector Store ID:** `{VECTOR_STORES[selected_store]}`")
                st.markdown(f"**æ¤œç´¢ã‚¯ã‚¨ãƒª:** {query}")
                st.markdown(f"**æ¤œç´¢æ–¹æ³•:** {final_metadata.get('method', 'unknown')}")

                # æ¤œç´¢å±¥æ­´ã«è¿½åŠ 
                history_item = {
                    "query"         : query,
                    "store_name"    : selected_store,
                    "timestamp"     : datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    "method"        : final_metadata.get('method', 'unknown'),
                    "result_preview": final_result[:200] + "..." if len(final_result) > 200 else final_result
                }

                # é‡è¤‡ãƒã‚§ãƒƒã‚¯
                if not any(item['query'] == query and item['store_name'] == selected_store
                           for item in st.session_state.search_history):
                    st.session_state.search_history.insert(0, history_item)
                    st.session_state.search_history = st.session_state.search_history[:50]  # æœ€æ–°50ä»¶ä¿æŒ

        elif submitted and not query.strip():
            st.error("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")

    with col2:
        if not st.session_state.current_query:
            st.header("ğŸ¤– æ¤œç´¢çµæœ")
            st.info("è³ªå•ã‚’å…¥åŠ›ã—ã¦æ¤œç´¢ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")

    # æ¤œç´¢å±¥æ­´ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    st.markdown("---")
    display_search_history()

    # ãƒ•ãƒƒã‚¿ãƒ¼
    st.markdown("---")
    st.markdown("**RAGæ¤œç´¢ãƒ†ã‚¹ãƒˆã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆAgent SDKç‰ˆï¼‰**")
    st.markdown("OpenAI Agent SDK ã‚’ä½¿ç”¨ã—ãŸæ¬¡ä¸–ä»£RAGã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³")


if __name__ == "__main__":
    main()
