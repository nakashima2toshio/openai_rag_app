# streamlit run 01_get_submenu_url.py

import streamlit as st
import requests
from bs4 import BeautifulSoup
import pandas as pd
from urllib.parse import urljoin
from io import StringIO

# Streamlitãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(page_title="ãƒ¡ãƒ‹ãƒ¥ãƒ¼URLæŠ½å‡º", page_icon="ğŸ”")

st.header("URLã‹ã‚‰ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã¨ãƒªãƒ³ã‚¯ã‚’CSVã§å–å¾—")

# URLå…¥åŠ›
url = st.text_input("å¯¾è±¡ã®URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:", value="https://openai.github.io/openai-agents-python/")

# CSVç”Ÿæˆé–¢æ•°
def extract_sidebar_links(url):
    response = requests.get(url)
    soup = BeautifulSoup(response.text, 'html.parser')

    sidebar = soup.find('nav', class_='menu')
    if not sidebar:
        st.error("ãƒ¡ãƒ‹ãƒ¥ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        return None

    links = sidebar.find_all('a', class_='menu__link')

    data = []
    for link in links:
        text = link.get_text(strip=True).replace('/', '_').replace(' ', '_')
        full_url = urljoin(url, link.get('href'))
        data.append([text, full_url])

    df = pd.DataFrame(data, columns=['ã‚¿ã‚¤ãƒˆãƒ«_ã‚µãƒ–ã‚¿ã‚¤ãƒˆãƒ«', 'URL'])
    return df

# CSVè¡¨ç¤ºã¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å‡¦ç†
if st.button("CSVãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"):
    df = extract_sidebar_links(url)
    if df is not None:
        st.write("å–å¾—ã—ãŸãƒ‡ãƒ¼ã‚¿:")
        st.dataframe(df)

        # CSVã¨ã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        csv_buffer = StringIO()
        df.to_csv(csv_buffer, index=False)
        csv_str = csv_buffer.getvalue()

        st.download_button(
            label="CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=csv_str,
            file_name='menu_links.csv',
            mime='text/csv',
        )
