# a30_010_make_vector_store_id.py
# OUTPUT/customer_support_faq.txt
# OUTPUT/medical_qa.txt
# OUTPUT/sciq_qa.txt
# OUTPUT/legal_qa.txt

import os
import re
import time
import json
from pathlib import Path
from typing import List, Optional
import logging

from openai import OpenAI
from openai.types.chat import ChatCompletionMessageParam, ChatCompletionSystemMessageParam, \
    ChatCompletionUserMessageParam, ChatCompletionAssistantMessageParam

from datasets import load_dataset
import pandas as pd
import tempfile
import textwrap
from pydantic import BaseModel, Field
from tqdm import tqdm

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from helper_st import (
        UIHelper, MessageManagerUI, ResponseProcessorUI,
        SessionStateManager, error_handler_ui, timer_ui,
        init_page, select_model, InfoPanelManager
    )
    from helper_api import (
        config, logger, TokenManager, OpenAIClient,
        EasyInputMessageParam, ResponseInputTextParam,
        ConfigManager, MessageManager, sanitize_key,
        error_handler, timer
    )
except ImportError as e:
    # streamlitãŒã‚¤ãƒ³ãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
    pass

BASE_DIR = Path(__file__).resolve().parent.parent  # Paslib
THIS_DIR = Path(__file__).resolve().parent  # Paslib


def get_embeddings_batch(texts: List[str], model: str = "text-embedding-3-small", batch_size: int = 100) -> List[
    Optional[List[float]]]:
    """
    OpenAI Embedding APIã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆãƒªã‚¹ãƒˆã‚’ãƒãƒƒãƒã§ãƒ™ã‚¯ãƒˆãƒ«åŒ–

    Args:
        texts: ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆã®ãƒªã‚¹ãƒˆ
        model: ä½¿ç”¨ã™ã‚‹embeddingãƒ¢ãƒ‡ãƒ« (æ¨å¥¨: text-embedding-3-small)
        batch_size: ä¸€åº¦ã®APIå‘¼ã³å‡ºã—ã§å‡¦ç†ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆæ•°ï¼ˆæœ€å¤§2048ï¼‰

    Returns:
        åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã®ãƒªã‚¹ãƒˆ
    """
    client = OpenAI()
    embeddings = []

    # ãƒ†ã‚­ã‚¹ãƒˆã‚’å‰å‡¦ç†ï¼ˆæ”¹è¡Œæ–‡å­—ã‚’ã‚¹ãƒšãƒ¼ã‚¹ã«ç½®æ›ï¼‰
    cleaned_texts = [text.replace("\n", " ") for text in texts]

    logger.info(f"Embeddingä½œæˆé–‹å§‹: {len(cleaned_texts)}ä»¶ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’{batch_size}ä»¶ãšã¤å‡¦ç†")

    # ãƒãƒƒãƒã”ã¨ã«å‡¦ç†
    for i in tqdm(range(0, len(cleaned_texts), batch_size), desc="Embeddingä½œæˆä¸­"):
        batch = cleaned_texts[i:i + batch_size]

        try:
            response = client.embeddings.create(
                input=batch,
                model=model,
                # dimensions=1024  # ã‚³ã‚¹ãƒˆåŠ¹ç‡ã‚’é‡è¦–ã™ã‚‹å ´åˆã¯æ¬¡å…ƒæ•°ã‚’å‰Šæ¸›
            )

            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰embeddingã‚’å–å¾—
            batch_embeddings = [data.embedding for data in response.data]
            embeddings.extend(batch_embeddings)

            logger.info(
                f"ãƒãƒƒãƒ {i // batch_size + 1}/{(len(cleaned_texts) - 1) // batch_size + 1}: {len(batch)}ä»¶å‡¦ç†å®Œäº†")

            # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾å¿œã®ãŸã‚ã®çŸ­ã„å¾…æ©Ÿ
            time.sleep(0.1)

        except Exception as e:
            logger.error(f"ãƒãƒƒãƒ {i // batch_size + 1}ã§ã‚¨ãƒ©ãƒ¼: {e}")
            # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã¯Noneã§åŸ‹ã‚ã‚‹
            embeddings.extend([None] * len(batch))

            # ä¸€æ™‚çš„ãªå•é¡Œã®å ´åˆã¯ãƒªãƒˆãƒ©ã‚¤
            time.sleep(2)

    return embeddings


def create_vector_store_from_dataframe(df_clean: pd.DataFrame, store_name: str = "Customer Support FAQ") -> Optional[
    str]:
    """
    DataFrameã‹ã‚‰Vector Storeã‚’ä½œæˆï¼ˆæœ€æ–°APIå¯¾å¿œç‰ˆï¼‰

    Args:
        df_clean: ã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°æ¸ˆã¿ã®DataFrame
        store_name: Vector Storeã®åå‰

    Returns:
        Vector Store IDï¼ˆæˆåŠŸæ™‚ï¼‰ã¾ãŸã¯Noneï¼ˆå¤±æ•—æ™‚ï¼‰
    """
    client = OpenAI()
    temp_file_path = None
    uploaded_file_id = None

    try:
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç”¨ã®JSONLãƒ•ã‚¡ã‚¤ãƒ«ã‚’æº–å‚™
        # æ‹¡å¼µå­ã‚’.txtã«å¤‰æ›´ï¼ˆOpenAI Files APIã®åˆ¶é™å¯¾å¿œï¼‰
        with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:
            for idx, row in df_clean.iterrows():
                # JSONLå½¢å¼ã§ãƒ‡ãƒ¼ã‚¿ã‚’æ›¸ãè¾¼ã¿ï¼ˆæ‹¡å¼µå­ã¯.txtã ãŒä¸­èº«ã¯JSONLï¼‰
                json_line = {
                    "id"  : f"faq_{idx}",
                    "text": row['combined_text']
                }
                temp_file.write(json.dumps(json_line, ensure_ascii=False) + '\n')

            temp_file_path = temp_file.name

        logger.info(f"JSONLãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆå®Œäº†: {temp_file_path}")

        # Step 1: ãƒ•ã‚¡ã‚¤ãƒ«ã‚’OpenAIã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆ.txtæ‹¡å¼µå­ã§ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼‰
        with open(temp_file_path, 'rb') as file:
            uploaded_file = client.files.create(
                file=file,
                purpose="assistants"
            )
            uploaded_file_id = uploaded_file.id

        logger.info(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†: File ID={uploaded_file_id}")

        # Step 2: Vector Storeã‚’ä½œæˆï¼ˆæœ€æ–°APIä»•æ§˜ï¼‰
        # å‹ãƒã‚§ãƒƒã‚¯ã®è­¦å‘Šã‚’é¿ã‘ã‚‹ãŸã‚ã€å‹•çš„ã«ä½œæˆ
        vector_store = client.vector_stores.create(
            name=store_name,
            file_ids=[uploaded_file_id],  # ãƒ•ã‚¡ã‚¤ãƒ«IDã‚’ç›´æ¥æŒ‡å®šã™ã‚‹æ–¹æ³•ã«å¤‰æ›´
            metadata={
                "created_by" : "customer_support_faq_processor",
                "version"    : "2025.1",
                "data_format": "jsonl_as_txt"
            }
        )

        logger.info(f"Vector Storeä½œæˆå®Œäº†: ID={vector_store.id}")

        # Step 3: ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†å®Œäº†ã‚’å¾…æ©Ÿ
        max_wait_time = 300  # æœ€å¤§5åˆ†å¾…æ©Ÿ
        wait_interval = 5  # 5ç§’é–“éš”ã§ãƒã‚§ãƒƒã‚¯
        waited_time = 0

        while waited_time < max_wait_time:
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ç¢ºèª
            file_status = client.vector_stores.files.retrieve(
                vector_store_id=vector_store.id,
                file_id=uploaded_file_id
            )

            logger.info(f"ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†çŠ¶æ³: {file_status.status} (å¾…æ©Ÿæ™‚é–“: {waited_time}ç§’)")

            if file_status.status == "completed":
                # Vector Storeå…¨ä½“ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ç¢ºèª
                updated_vector_store = client.vector_stores.retrieve(vector_store.id)

                logger.info(f"âœ… Vector Storeä½œæˆå®Œäº†:")
                logger.info(f"  - ID: {vector_store.id}")
                logger.info(f"  - Name: {vector_store.name}")
                logger.info(f"  - ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†çŠ¶æ³: {file_status.status}")
                logger.info(f"  - ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {updated_vector_store.file_counts.total}")
                logger.info(f"  - å®Œäº†ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {updated_vector_store.file_counts.completed}")
                logger.info(f"  - å¤±æ•—ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {updated_vector_store.file_counts.failed}")
                logger.info(f"  - ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ä½¿ç”¨é‡: {updated_vector_store.usage_bytes} bytes")

                return vector_store.id

            elif file_status.status == "failed":
                logger.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†å¤±æ•—: {file_status.last_error}")
                return None

            elif file_status.status in ["in_progress", "cancelling"]:
                # å‡¦ç†ä¸­ã®å ´åˆã¯ç¶™ç¶šã—ã¦å¾…æ©Ÿ
                time.sleep(wait_interval)
                waited_time += wait_interval
            else:
                logger.warning(f"âš ï¸ äºˆæœŸã—ãªã„ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {file_status.status}")
                time.sleep(wait_interval)
                waited_time += wait_interval

        # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã®å ´åˆ
        logger.error(f"âŒ Vector Storeä½œæˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ (åˆ¶é™æ™‚é–“: {max_wait_time}ç§’)")
        return None

    except Exception as e:
        logger.error(f"Vector Storeä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
        logger.error(f"ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—: {type(e).__name__}")

        # å…·ä½“çš„ãªã‚¨ãƒ©ãƒ¼å¯¾å¿œã®ææ¡ˆ
        if "authentication" in str(e).lower():
            logger.error("ğŸ”‘ APIã‚­ãƒ¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚ç’°å¢ƒå¤‰æ•°OPENAI_API_KEYãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã€‚")
        elif "quota" in str(e).lower() or "limit" in str(e).lower():
            logger.error("ğŸ’³ APIã‚¯ã‚ªãƒ¼ã‚¿ã¾ãŸã¯ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«é”ã—ã¦ã„ã¾ã™ã€‚æ–™é‡‘ãƒ—ãƒ©ãƒ³ã¾ãŸã¯ä½¿ç”¨é‡ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        elif "file" in str(e).lower():
            logger.error("ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«é–¢é€£ã®ã‚¨ãƒ©ãƒ¼ã§ã™ã€‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚„ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        elif "extension" in str(e).lower() or "format" in str(e).lower():
            logger.error("ğŸ“„ ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­ã¾ãŸã¯ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®å•é¡Œã§ã™ã€‚ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹å½¢å¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

        return None

    finally:
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
        if temp_file_path and os.path.exists(temp_file_path):
            os.unlink(temp_file_path)
            logger.info("ğŸ—‘ï¸ ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")


def create_vector_store_with_advanced_options(df_clean: pd.DataFrame,
                                              store_name: str = "Customer Support FAQ") -> Optional[str]:
    """
    é«˜åº¦ãªã‚ªãƒ—ã‚·ãƒ§ãƒ³ä»˜ãã§Vector Storeã‚’ä½œæˆï¼ˆå‹å®‰å…¨ç‰ˆï¼‰

    Args:
        df_clean: ã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°æ¸ˆã¿ã®DataFrame
        store_name: Vector Storeã®åå‰

    Returns:
        Vector Store IDï¼ˆæˆåŠŸæ™‚ï¼‰ã¾ãŸã¯Noneï¼ˆå¤±æ•—æ™‚ï¼‰
    """
    client = OpenAI()
    temp_file_path = None
    uploaded_file_id = None

    try:
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:
            for idx, row in df_clean.iterrows():
                json_line = {
                    "id"  : f"faq_{idx}",
                    "text": row['combined_text']
                }
                temp_file.write(json.dumps(json_line, ensure_ascii=False) + '\n')
            temp_file_path = temp_file.name

        logger.info(f"JSONLãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆå®Œäº†: {temp_file_path}")

        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        with open(temp_file_path, 'rb') as file:
            uploaded_file = client.files.create(
                file=file,
                purpose="assistants"
            )
            uploaded_file_id = uploaded_file.id

        logger.info(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†: File ID={uploaded_file_id}")

        # Vector Storeä½œæˆï¼ˆã‚·ãƒ³ãƒ—ãƒ«ç‰ˆ - å‹ã‚¨ãƒ©ãƒ¼ã‚’å›é¿ï¼‰
        vector_store = client.vector_stores.create(
            name=store_name,
            metadata={
                "created_by" : "customer_support_faq_processor",
                "version"    : "2025.1",
                "data_format": "jsonl_as_txt"
            }
        )

        logger.info(f"Vector Storeä½œæˆå®Œäº†: ID={vector_store.id}")

        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’Vector Storeã«è¿½åŠ 
        vector_store_file = client.vector_stores.files.create(
            vector_store_id=vector_store.id,
            file_id=uploaded_file_id
        )

        logger.info(f"Vector StoreFileãƒªãƒ³ã‚¯ä½œæˆ: {vector_store_file.id}")

        # å‡¦ç†å®Œäº†å¾…æ©Ÿ
        max_wait_time = 300
        wait_interval = 5
        waited_time = 0

        while waited_time < max_wait_time:
            file_status = client.vector_stores.files.retrieve(
                vector_store_id=vector_store.id,
                file_id=uploaded_file_id
            )

            logger.info(f"ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†çŠ¶æ³: {file_status.status} (å¾…æ©Ÿæ™‚é–“: {waited_time}ç§’)")

            if file_status.status == "completed":
                updated_vector_store = client.vector_stores.retrieve(vector_store.id)

                logger.info(f"âœ… Vector Storeä½œæˆå®Œäº†:")
                logger.info(f"  - ID: {vector_store.id}")
                logger.info(f"  - Name: {vector_store.name}")
                logger.info(f"  - ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†çŠ¶æ³: {file_status.status}")
                logger.info(f"  - ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {updated_vector_store.file_counts.total}")

                return vector_store.id

            elif file_status.status == "failed":
                logger.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†å¤±æ•—: {file_status.last_error}")
                return None

            elif file_status.status in ["in_progress", "cancelling"]:
                time.sleep(wait_interval)
                waited_time += wait_interval
            else:
                logger.warning(f"âš ï¸ äºˆæœŸã—ãªã„ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {file_status.status}")
                time.sleep(wait_interval)
                waited_time += wait_interval

        logger.error(f"âŒ Vector Storeä½œæˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ (åˆ¶é™æ™‚é–“: {max_wait_time}ç§’)")
        return None

    except Exception as e:
        logger.error(f"Vector Storeä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
        return None

    finally:
        if temp_file_path and os.path.exists(temp_file_path):
            os.unlink(temp_file_path)
            logger.info("ğŸ—‘ï¸ ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
