#
# ä»£è¡¨çš„ãªMCPã‚µãƒ¼ãƒãƒ¼ä¸€è¦§
# å…¬å¼ã‚µãƒ¼ãƒãƒ¼ï¼ˆAnthropic/OpenAIæä¾›ï¼‰
# ------------------------------------------------
# File System - ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹
# GitHub - GitHubãƒªãƒã‚¸ãƒˆãƒªç®¡ç†ã¨APIçµ±åˆ
# Google Drive - Google Driveãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ã‚¯ã‚»ã‚¹ã¨æ¤œç´¢
# Slack - Slackãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹çµ±åˆã¨ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ³ã‚°
# PostgreSQL - ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¢ã‚¯ã‚»ã‚¹ï¼ˆèª­ã¿å–ã‚Šå°‚ç”¨ï¼‰
# Puppeteer - ãƒ–ãƒ©ã‚¦ã‚¶è‡ªå‹•åŒ–ã¨Webã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°
# Git - Gitãƒªãƒã‚¸ãƒˆãƒªã®èª­ã¿å–ã‚Šãƒ»æ¤œç´¢ãƒ»æ“ä½œ
# Google Maps - ä½ç½®æƒ…å ±ã‚µãƒ¼ãƒ“ã‚¹ã€ãƒ«ãƒ¼ãƒˆæ¤œç´¢
# Brave Search - Braveæ¤œç´¢APIã‚’ä½¿ç”¨ã—ãŸWebæ¤œç´¢
# SQLite - SQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ“ä½œ
# GitHub - wong2/awesome-mcp-servers: A curated list of Model Context Protocol (MCP) servers
# ------------------------------------------------
# ã‚µãƒ¼ãƒ‰ãƒ‘ãƒ¼ãƒ†ã‚£è£½äººæ°—ã‚µãƒ¼ãƒãƒ¼
# ------------------------------------------------
# Docker - Dockerã‚³ãƒ³ãƒ†ãƒŠç®¡ç†
# Notion - Notionãƒšãƒ¼ã‚¸ã¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ“ä½œ
# Spotify - Spotify APIçµ±åˆï¼ˆéŸ³æ¥½åˆ¶å¾¡ï¼‰
# Microsoft 365 - Officeã€Outlookã€Excelçµ±åˆ
# Raygun - ã‚¨ãƒ©ãƒ¼ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ã¨ç›£è¦–
# Cloudflare - ã‚¨ãƒƒã‚¸ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã¨CDN
# Redis - Redisã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢æ“ä½œ
# MySQL - MySQLãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±åˆ
# Google Sheets - Googleã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆæ“ä½œ
# Email (SMTP) - ãƒ¡ãƒ¼ãƒ«é€ä¿¡æ©Ÿèƒ½
# HuggingfaceGitHub
# ------------------------------------------------
"""
OpenAI Responses API + MCP (Model Context Protocol) ã‚µãƒ¼ãƒãƒ¼åˆ©ç”¨ä¾‹ - ä¿®æ­£ç‰ˆ
=================================================================

ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã€OpenAI Responses APIã§MCPã‚µãƒ¼ãƒãƒ¼ã‚’åˆ©ç”¨ã™ã‚‹
æ§˜ã€…ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã®ã‚³ãƒ¼ãƒ‰ä¾‹ã‚’æä¾›ã—ã¾ã™ã€‚

å‰ææ¡ä»¶:
- OpenAI API Key (OPENAI_API_KEYç’°å¢ƒå¤‰æ•°)
- å„MCPã‚µãƒ¼ãƒãƒ¼ã®API Keyï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
- OpenAI Python SDK version 1.50.0ä»¥ä¸Š

ä¿®æ­£å†…å®¹:
- messages â†’ input ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«å¤‰æ›´
- MCPãƒ„ãƒ¼ãƒ«è¨­å®šã«server_labelã¨require_approvalã‚’è¿½åŠ 
- ãƒ¬ã‚¹ãƒãƒ³ã‚¹å‡¦ç†ã‚’æ–°ã—ã„APIä»•æ§˜ã«å¯¾å¿œ
"""
"""
OpenAI API + MCP (Model Context Protocol) å®Œå…¨å‹å¯¾å¿œç‰ˆ
====================================================

ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã€OpenAI APIã®é©åˆ‡ãªå‹ä»˜ãã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½¿ç”¨ã—ã¦
MCPã‚µãƒ¼ãƒãƒ¼ã‚’åˆ©ç”¨ã™ã‚‹å®Œå…¨ãªã‚³ãƒ¼ãƒ‰ä¾‹ã‚’æä¾›ã—ã¾ã™ã€‚

å‰ææ¡ä»¶:
- OpenAI API Key (OPENAI_API_KEYç’°å¢ƒå¤‰æ•°)
- OpenAI Python SDK version 1.60.0ä»¥ä¸Š
- å„MCPã‚µãƒ¼ãƒãƒ¼ã®API Keyï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰

å‹å¯¾å¿œå†…å®¹:
- ã™ã¹ã¦ã®ãƒ„ãƒ¼ãƒ«ã§é©åˆ‡ãªå‹ä»˜ãã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½¿ç”¨
- HostedMCPToolã€WebSearchToolç­‰ã®æ­£å¼ãªå‹å®šç¾©
- å‹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼ã®å®Œå…¨è§£æ±º
- Pydantic BaseModelã‚’ä½¿ç”¨ã—ãŸå‹å®‰å…¨ãªå®Ÿè£…
"""

import os
import json
import asyncio
from typing import Optional, List, Dict, Any, Union
from pathlib import Path
from dataclasses import dataclass
from abc import ABC, abstractmethod

# OpenAIé–¢é€£ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from openai import OpenAI, AsyncOpenAI

# å‹å®šç¾©ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    # OpenAI Responses APIç”¨ã®å‹
    from openai.types.responses import (
        ResponseCreateParams,
        Response as OpenAIResponse
    )

    # çµ„ã¿è¾¼ã¿ãƒ„ãƒ¼ãƒ«å‹ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    from openai.types.responses.create_params import (
        Tool as ResponseTool,
        MCPTool,
        CodeInterpreterTool,
        WebSearchPreviewTool,
        ImageGenerationTool
    )

    TYPES_AVAILABLE = True
    print("âœ… OpenAIå‹å®šç¾©ãŒåˆ©ç”¨å¯èƒ½ã§ã™")

except ImportError:
    print("âš ï¸ OpenAIå‹å®šç¾©ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã§ãã¾ã›ã‚“ã€‚fallbackå®Ÿè£…ã‚’ä½¿ç”¨ã—ã¾ã™")
    TYPES_AVAILABLE = False
    ResponseTool = Dict[str, Any]
    MCPTool = Dict[str, Any]
    CodeInterpreterTool = Dict[str, Any]
    WebSearchPreviewTool = Dict[str, Any]
    ImageGenerationTool = Dict[str, Any]

# Pydantic for data validation
try:
    from pydantic import BaseModel, Field

    PYDANTIC_AVAILABLE = True
except ImportError:
    print("âš ï¸ PydanticãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
    PYDANTIC_AVAILABLE = False
    BaseModel = object

# OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
client = OpenAI()
async_client = AsyncOpenAI()


# ================================================
# å‹å®šç¾©ã¨ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹
# ================================================

@dataclass
class MCPServerConfig:
    """MCPã‚µãƒ¼ãƒãƒ¼è¨­å®šã®å‹å®‰å…¨ãªãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹"""
    server_url: str
    server_label: str
    headers: Optional[Dict[str, str]] = None
    allowed_tools: Optional[List[str]] = None
    require_approval: str = "never"

    def __post_init__(self):
        if self.headers is None:
            self.headers = {}
        if self.allowed_tools is None:
            self.allowed_tools = []


@dataclass
class ProjectConfig:
    """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè¨­å®š"""
    base_dir: Path
    this_dir: Path
    datasets_dir: Path
    helper_dir: Path
    page_title: str = "OpenAI API + MCP Learning"
    page_icon: str = "ğŸ¤–"
    default_model: str = "gpt-4o"
    available_models: List[str] = None

    def __post_init__(self):
        if self.available_models is None:
            self.available_models = [
                "gpt-4o", "gpt-4o-mini", "gpt-4", "gpt-4-turbo"
            ]
        self.datasets_dir.mkdir(exist_ok=True, parents=True)


# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè¨­å®šã®åˆæœŸåŒ–
BASE_DIR = Path(__file__).resolve().parent.parent
THIS_DIR = Path(__file__).resolve().parent

config = ProjectConfig(
    base_dir=BASE_DIR,
    this_dir=THIS_DIR,
    datasets_dir=BASE_DIR / 'datasets',
    helper_dir=BASE_DIR / 'a0_common_helper'
)


# ================================================
# å‹å®‰å…¨ãªãƒ„ãƒ¼ãƒ«ãƒ•ã‚¡ã‚¯ãƒˆãƒªãƒ¼
# ================================================

class TypedToolFactory:
    """å‹å®‰å…¨ãªãƒ„ãƒ¼ãƒ«ä½œæˆãƒ•ã‚¡ã‚¯ãƒˆãƒªãƒ¼ã‚¯ãƒ©ã‚¹"""

    @staticmethod
    def create_mcp_tool(config: MCPServerConfig) -> Union[MCPTool, Dict[str, Any]]:
        """å‹å®‰å…¨ãªMCPãƒ„ãƒ¼ãƒ«ã‚’ä½œæˆ"""
        if TYPES_AVAILABLE:
            # æ­£å¼ãªå‹ã‚’ä½¿ç”¨
            return MCPTool(
                type="mcp",
                server_label=config.server_label,
                server_url=config.server_url,
                headers=config.headers,
                allowed_tools=config.allowed_tools,
                require_approval=config.require_approval
            )
        else:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: è¾æ›¸å½¢å¼
            return {
                "type"            : "mcp",
                "server_label"    : config.server_label,
                "server_url"      : config.server_url,
                "headers"         : config.headers,
                "allowed_tools"   : config.allowed_tools,
                "require_approval": config.require_approval
            }

    @staticmethod
    def create_code_interpreter_tool() -> Union[CodeInterpreterTool, Dict[str, Any]]:
        """å‹å®‰å…¨ãªã‚³ãƒ¼ãƒ‰ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ—ãƒªã‚¿ãƒ¼ãƒ„ãƒ¼ãƒ«ã‚’ä½œæˆ"""
        if TYPES_AVAILABLE:
            return CodeInterpreterTool(type="code_interpreter")
        else:
            return {"type": "code_interpreter"}

    @staticmethod
    def create_web_search_tool() -> Union[WebSearchPreviewTool, Dict[str, Any]]:
        """å‹å®‰å…¨ãªWebæ¤œç´¢ãƒ„ãƒ¼ãƒ«ã‚’ä½œæˆ"""
        if TYPES_AVAILABLE:
            return WebSearchPreviewTool(type="web_search_preview")
        else:
            return {"type": "web_search_preview"}

    @staticmethod
    def create_image_generation_tool() -> Union[ImageGenerationTool, Dict[str, Any]]:
        """å‹å®‰å…¨ãªç”»åƒç”Ÿæˆãƒ„ãƒ¼ãƒ«ã‚’ä½œæˆ"""
        if TYPES_AVAILABLE:
            return ImageGenerationTool(type="image_generation")
        else:
            return {"type": "image_generation"}


# ================================================
# åŸºåº•ã‚¯ãƒ©ã‚¹ï¼ˆå‹å®‰å…¨ç‰ˆï¼‰
# ================================================

class BaseTypedDemo(ABC):
    """å‹å®‰å…¨ãªãƒ‡ãƒ¢æ©Ÿèƒ½ã®åŸºåº•ã‚¯ãƒ©ã‚¹"""

    def __init__(self, demo_name: str):
        self.demo_name = demo_name
        self.client = client
        self.async_client = async_client
        self.tool_factory = TypedToolFactory()

    def validate_environment(self) -> List[str]:
        """ç’°å¢ƒè¨­å®šã®æ¤œè¨¼"""
        issues = []
        if not os.getenv("OPENAI_API_KEY"):
            issues.append("OPENAI_API_KEY not set")
        return issues

    @abstractmethod
    def create_tools(self) -> List[Union[ResponseTool, Dict[str, Any]]]:
        """ã“ã®ãƒ‡ãƒ¢ã§ä½¿ç”¨ã™ã‚‹ãƒ„ãƒ¼ãƒ«ã‚’ä½œæˆ"""
        pass

    @abstractmethod
    def get_input_message(self) -> str:
        """å…¥åŠ›ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å–å¾—"""
        pass

    def run_sync(self) -> OpenAIResponse:
        """åŒæœŸå®Ÿè¡Œ"""
        tools = self.create_tools()
        input_message = self.get_input_message()

        try:
            response = self.client.responses.create(
                model=config.default_model,
                input=input_message,
                tools=tools
            )
            return response
        except Exception as e:
            print(f"Error in {self.demo_name}: {e}")
            raise

    async def run_async(self) -> OpenAIResponse:
        """éåŒæœŸå®Ÿè¡Œ"""
        tools = self.create_tools()
        input_message = self.get_input_message()

        try:
            response = await self.async_client.responses.create(
                model=config.default_model,
                input=input_message,
                tools=tools
            )
            return response
        except Exception as e:
            print(f"Error in {self.demo_name}: {e}")
            raise


# ================================================
# å…·ä½“çš„ãªãƒ‡ãƒ¢å®Ÿè£…ï¼ˆå‹å®‰å…¨ç‰ˆï¼‰
# ================================================

class GitHubMCPDemo(BaseTypedDemo):
    """GitHub MCPã‚µãƒ¼ãƒãƒ¼ã‚’ä½¿ç”¨ã™ã‚‹ãƒ‡ãƒ¢ï¼ˆå‹å®‰å…¨ç‰ˆï¼‰"""

    def __init__(self):
        super().__init__("GitHub MCP Demo (Typed)")

    def create_tools(self) -> List[Union[ResponseTool, Dict[str, Any]]]:
        """GitHub MCPãƒ„ãƒ¼ãƒ«ã‚’ä½œæˆ"""
        github_config = MCPServerConfig(
            server_url="https://github-mcp-server.example.com",
            server_label="github",
            headers={"Authorization": f"Bearer {os.getenv('GITHUB_TOKEN')}"},
            allowed_tools=[
                "search_repository",
                "get_file_content",
                "list_files",
                "get_commit_info"
            ],
            require_approval="never"
        )

        return [
            self.tool_factory.create_mcp_tool(github_config)
        ]

    def get_input_message(self) -> str:
        return "Please search for Python files in my repository and show me the main functions and classes."


class MultiMCPDemo(BaseTypedDemo):
    """è¤‡æ•°MCPã‚µãƒ¼ãƒãƒ¼ã‚’ä½¿ç”¨ã™ã‚‹ãƒ‡ãƒ¢ï¼ˆå‹å®‰å…¨ç‰ˆï¼‰"""

    def __init__(self):
        super().__init__("Multi MCP Demo (Typed)")

    def create_tools(self) -> List[Union[ResponseTool, Dict[str, Any]]]:
        """è¤‡æ•°ã®MCPãƒ„ãƒ¼ãƒ«ã‚’ä½œæˆ"""
        # GitHub MCPè¨­å®š
        github_config = MCPServerConfig(
            server_url="https://github-mcp-server.example.com",
            server_label="github",
            headers={"Authorization": f"Bearer {os.getenv('GITHUB_TOKEN')}"},
            allowed_tools=[
                "get_recent_commits",
                "get_file_content",
                "get_commit_diff"
            ],
            require_approval="never"
        )

        # Slack MCPè¨­å®š
        slack_config = MCPServerConfig(
            server_url="https://slack-mcp-server.example.com",
            server_label="slack",
            headers={"Authorization": f"Bearer {os.getenv('SLACK_BOT_TOKEN')}"},
            allowed_tools=[
                "post_message",
                "list_channels",
                "get_channel_history"
            ],
            require_approval="never"
        )

        # Webæ¤œç´¢ãƒ„ãƒ¼ãƒ«ã‚‚è¿½åŠ 
        return [
            self.tool_factory.create_mcp_tool(github_config),
            self.tool_factory.create_mcp_tool(slack_config),
            self.tool_factory.create_web_search_tool()
        ]

    def get_input_message(self) -> str:
        return """
        Please follow these steps:
        1. Use GitHub MCP to examine recent commits in the repository
        2. Analyze the code for potential issues or improvements
        3. Use web search if you need additional information about best practices
        4. Use Slack MCP to post a summary to the #code-review channel

        Focus on: security issues, performance problems, and code quality.
        """


class DatabaseAnalysisDemo(BaseTypedDemo):
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆ†æãƒ‡ãƒ¢ï¼ˆå‹å®‰å…¨ç‰ˆï¼‰"""

    def __init__(self):
        super().__init__("Database Analysis Demo (Typed)")

    def create_tools(self) -> List[Union[ResponseTool, Dict[str, Any]]]:
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆ†æç”¨ãƒ„ãƒ¼ãƒ«ã‚’ä½œæˆ"""
        # PostgreSQL MCPè¨­å®š
        db_config = MCPServerConfig(
            server_url="https://postgresql-mcp.example.com",
            server_label="postgresql",
            headers={"Authorization": f"Bearer {os.getenv('DB_API_KEY')}"},
            allowed_tools=[
                "execute_query",
                "get_schema",
                "list_tables",
                "describe_table"
            ],
            require_approval="never"
        )

        return [
            self.tool_factory.create_mcp_tool(db_config),
            self.tool_factory.create_code_interpreter_tool()
        ]

    def get_input_message(self) -> str:
        return """
        You are a data analyst. Please:
        1. Examine the database schema using PostgreSQL MCP
        2. Query sales data from the last 30 days
        3. Calculate key metrics (total sales, average order value, top products) using code interpreter
        4. Create visualizations to show trends
        5. Provide insights and recommendations

        Use proper SQL practices and explain your analysis process.
        """


class FileManagementDemo(BaseTypedDemo):
    """ãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç†ãƒ‡ãƒ¢ï¼ˆå‹å®‰å…¨ç‰ˆï¼‰"""

    def __init__(self):
        super().__init__("File Management Demo (Typed)")

    def create_tools(self) -> List[Union[ResponseTool, Dict[str, Any]]]:
        """ãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç†ç”¨ãƒ„ãƒ¼ãƒ«ã‚’ä½œæˆ"""
        # File System MCPè¨­å®š
        filesystem_config = MCPServerConfig(
            server_url="http://localhost:8000/filesystem",
            server_label="filesystem",
            headers={},
            allowed_tools=[
                "list_files",
                "read_file",
                "create_directory",
                "get_file_info"
            ],
            require_approval="always"  # ãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œã¯æ‰¿èªå¿…é ˆ
        )

        # Google Drive MCPè¨­å®š
        gdrive_config = MCPServerConfig(
            server_url="https://gdrive-mcp.example.com",
            server_label="gdrive",
            headers={"Authorization": f"Bearer {os.getenv('GOOGLE_DRIVE_TOKEN')}"},
            allowed_tools=[
                "upload_file",
                "create_folder",
                "search_files",
                "get_file_metadata"
            ],
            require_approval="never"
        )

        return [
            self.tool_factory.create_mcp_tool(filesystem_config),
            self.tool_factory.create_mcp_tool(gdrive_config)
        ]

    def get_input_message(self) -> str:
        return """
        You are a file management assistant. Please help the user:
        1. Organize local files by type and date
        2. Backup important documents to Google Drive
        3. Create a summary report of the file organization

        Always ask for confirmation before moving or deleting files.
        The user wants to organize their Downloads folder and backup documents.
        """


class WebScrapingAnalysisDemo(BaseTypedDemo):
    """Webã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°åˆ†æãƒ‡ãƒ¢ï¼ˆå‹å®‰å…¨ç‰ˆï¼‰"""

    def __init__(self):
        super().__init__("Web Scraping Analysis Demo (Typed)")

    def create_tools(self) -> List[Union[ResponseTool, Dict[str, Any]]]:
        """Webã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°åˆ†æç”¨ãƒ„ãƒ¼ãƒ«ã‚’ä½œæˆ"""
        # Puppeteer MCPè¨­å®š
        puppeteer_config = MCPServerConfig(
            server_url="https://puppeteer-mcp.example.com",
            server_label="puppeteer",
            headers={},
            allowed_tools=[
                "navigate_to_page",
                "extract_text",
                "take_screenshot",
                "wait_for_element",
                "get_page_content"
            ],
            require_approval="never"
        )

        return [
            self.tool_factory.create_mcp_tool(puppeteer_config),
            self.tool_factory.create_web_search_tool(),
            self.tool_factory.create_code_interpreter_tool()
        ]

    def get_input_message(self) -> str:
        return """
        You are a market research analyst. Please:
        1. Use web search to find competitor websites selling yoga pants
        2. Use Puppeteer MCP to scrape product pricing data from competitor websites
        3. Use code interpreter to analyze price trends and patterns
        4. Generate a competitive analysis report with visualizations

        Focus on accuracy and provide data sources for all findings.
        Research pricing for yoga pants and create a competitive analysis.
        """


class ComprehensiveAnalysisDemo(BaseTypedDemo):
    """åŒ…æ‹¬çš„åˆ†æãƒ‡ãƒ¢ï¼ˆã™ã¹ã¦ã®ãƒ„ãƒ¼ãƒ«å‹ã‚’ä½¿ç”¨ï¼‰"""

    def __init__(self):
        super().__init__("Comprehensive Analysis Demo (All Tool Types)")

    def create_tools(self) -> List[Union[ResponseTool, Dict[str, Any]]]:
        """ã™ã¹ã¦ã®ç¨®é¡ã®ãƒ„ãƒ¼ãƒ«ã‚’ä½œæˆ"""
        # è¤‡æ•°ã®MCPã‚µãƒ¼ãƒãƒ¼è¨­å®š
        github_config = MCPServerConfig(
            server_url="https://github-mcp-server.example.com",
            server_label="github",
            headers={"Authorization": f"Bearer {os.getenv('GITHUB_TOKEN')}"},
            allowed_tools=["search_repository", "get_file_content"],
            require_approval="never"
        )

        db_config = MCPServerConfig(
            server_url="https://postgresql-mcp.example.com",
            server_label="database",
            headers={"Authorization": f"Bearer {os.getenv('DB_API_KEY')}"},
            allowed_tools=["execute_query", "get_schema"],
            require_approval="never"
        )

        # ã™ã¹ã¦ã®ãƒ„ãƒ¼ãƒ«å‹ã‚’å«ã‚€
        return [
            self.tool_factory.create_mcp_tool(github_config),
            self.tool_factory.create_mcp_tool(db_config),
            self.tool_factory.create_web_search_tool(),
            self.tool_factory.create_code_interpreter_tool(),
            self.tool_factory.create_image_generation_tool()
        ]

    def get_input_message(self) -> str:
        return """
        Please perform a comprehensive analysis:

        1. Use GitHub MCP to analyze our codebase structure
        2. Use Database MCP to get performance metrics
        3. Use web search to research industry best practices
        4. Use code interpreter to process and visualize the data
        5. Generate charts and diagrams with image generation
        6. Create a comprehensive report with recommendations

        Focus on: code quality, performance, scalability, and comparison with industry standards.
        """


# ================================================
# ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¯¾å¿œãƒ‡ãƒ¢ï¼ˆå‹å®‰å…¨ç‰ˆï¼‰
# ================================================

class TypedStreamingDemo(BaseTypedDemo):
    """å‹å®‰å…¨ãªã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ‡ãƒ¢"""

    def __init__(self):
        super().__init__("Typed Streaming Demo")

    def create_tools(self) -> List[Union[ResponseTool, Dict[str, Any]]]:
        """ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ç”¨ãƒ„ãƒ¼ãƒ«ã‚’ä½œæˆ"""
        gdrive_config = MCPServerConfig(
            server_url="https://gdrive-mcp.example.com",
            server_label="gdrive",
            headers={"Authorization": f"Bearer {os.getenv('GOOGLE_DRIVE_TOKEN')}"},
            allowed_tools=[
                "search_files",
                "get_file_content",
                "list_recent_files"
            ],
            require_approval="never"
        )

        return [
            self.tool_factory.create_mcp_tool(gdrive_config),
            self.tool_factory.create_web_search_tool()
        ]

    def get_input_message(self) -> str:
        return "Search my Google Drive for recent presentations and summarize their contents. Also search the web for related industry trends."

    async def run_streaming(self) -> str:
        """ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å®Ÿè¡Œ"""
        tools = self.create_tools()
        input_message = self.get_input_message()

        try:
            stream = await self.async_client.responses.create(
                model=config.default_model,
                input=input_message,
                tools=tools,
                stream=True
            )

            full_response = ""
            async for chunk in stream:
                if hasattr(chunk, 'choices') and chunk.choices:
                    choice = chunk.choices[0]
                    if hasattr(choice, 'delta') and hasattr(choice.delta, 'content'):
                        if choice.delta.content:
                            content = choice.delta.content
                            full_response += content
                            print(content, end='', flush=True)

            return full_response

        except Exception as e:
            print(f"Streaming error: {e}")
            raise


# ================================================
# ã‚«ã‚¹ã‚¿ãƒ é–¢æ•°ãƒ„ãƒ¼ãƒ«ï¼ˆå‹å®‰å…¨ç‰ˆï¼‰
# ================================================

if PYDANTIC_AVAILABLE:
    class CalculationRequest(BaseModel):
        """è¨ˆç®—ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®å‹å®šç¾©"""
        data: List[float] = Field(..., description="è¨ˆç®—å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ãƒªã‚¹ãƒˆ")
        metric_type: str = Field(default="average", description="ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®ç¨®é¡")


    class AnalysisResult(BaseModel):
        """åˆ†æçµæœã®å‹å®šç¾©"""
        metric_value: float = Field(..., description="è¨ˆç®—ã•ã‚ŒãŸãƒ¡ãƒˆãƒªã‚¯ã‚¹å€¤")
        data_count: int = Field(..., description="ãƒ‡ãƒ¼ã‚¿ç‚¹ã®æ•°")
        metric_type: str = Field(..., description="ä½¿ç”¨ã•ã‚ŒãŸãƒ¡ãƒˆãƒªã‚¯ã‚¹ç¨®é¡")


def calculate_metrics_typed(data: List[float], metric_type: str = "average") -> Dict[str, Any]:
    """
    å‹å®‰å…¨ãªæ•°å€¤ãƒ‡ãƒ¼ã‚¿ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—é–¢æ•°

    Args:
        data: è¨ˆç®—å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ãƒªã‚¹ãƒˆ
        metric_type: ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®ç¨®é¡ ("average", "sum", "max", "min")

    Returns:
        è¨ˆç®—çµæœã®è¾æ›¸
    """
    if not data:
        return {"error": "ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™", "metric_value": 0, "data_count": 0}

    if metric_type == "average":
        value = sum(data) / len(data)
    elif metric_type == "sum":
        value = sum(data)
    elif metric_type == "max":
        value = max(data)
    elif metric_type == "min":
        value = min(data)
    else:
        return {"error": f"æœªçŸ¥ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ç¨®é¡: {metric_type}", "metric_value": 0, "data_count": len(data)}

    return {
        "metric_value": value,
        "data_count"  : len(data),
        "metric_type" : metric_type,
        "success"     : True
    }


# ================================================
# ãƒ‡ãƒ¢ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ï¼ˆå‹å®‰å…¨ç‰ˆï¼‰
# ================================================

class TypedDemoManager:
    """å‹å®‰å…¨ãªãƒ‡ãƒ¢ç®¡ç†ã‚¯ãƒ©ã‚¹"""

    def __init__(self):
        self.demos: Dict[str, BaseTypedDemo] = {
            "github_mcp"       : GitHubMCPDemo(),
            "multi_mcp"        : MultiMCPDemo(),
            "database_analysis": DatabaseAnalysisDemo(),
            "file_management"  : FileManagementDemo(),
            "web_scraping"     : WebScrapingAnalysisDemo(),
            "comprehensive"    : ComprehensiveAnalysisDemo(),
            "streaming"        : TypedStreamingDemo()
        }

    def add_demo(self, name: str, demo: BaseTypedDemo):
        """æ–°ã—ã„ãƒ‡ãƒ¢ã‚’è¿½åŠ """
        self.demos[name] = demo

    def list_demos(self) -> List[str]:
        """åˆ©ç”¨å¯èƒ½ãªãƒ‡ãƒ¢ã®ãƒªã‚¹ãƒˆã‚’å–å¾—"""
        return list(self.demos.keys())

    def run_demo_sync(self, demo_name: str) -> OpenAIResponse:
        """ãƒ‡ãƒ¢ã‚’åŒæœŸå®Ÿè¡Œ"""
        if demo_name not in self.demos:
            raise ValueError(f"Unknown demo: {demo_name}")

        demo = self.demos[demo_name]
        issues = demo.validate_environment()

        if issues:
            print(f"Environment issues for {demo_name}:")
            for issue in issues:
                print(f"  - {issue}")

        return demo.run_sync()

    async def run_demo_async(self, demo_name: str) -> OpenAIResponse:
        """ãƒ‡ãƒ¢ã‚’éåŒæœŸå®Ÿè¡Œ"""
        if demo_name not in self.demos:
            raise ValueError(f"Unknown demo: {demo_name}")

        demo = self.demos[demo_name]
        issues = demo.validate_environment()

        if issues:
            print(f"Environment issues for {demo_name}:")
            for issue in issues:
                print(f"  - {issue}")

        return await demo.run_async()

    async def run_streaming_demo(self, demo_name: str = "streaming") -> str:
        """ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ‡ãƒ¢ã‚’å®Ÿè¡Œ"""
        if demo_name not in self.demos:
            raise ValueError(f"Unknown demo: {demo_name}")

        demo = self.demos[demo_name]
        if isinstance(demo, TypedStreamingDemo):
            return await demo.run_streaming()
        else:
            raise ValueError(f"Demo {demo_name} does not support streaming")


# ================================================
# ãƒ¬ã‚¹ãƒãƒ³ã‚¹å‡¦ç†ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆå‹å®‰å…¨ç‰ˆï¼‰
# ================================================

class TypedResponseProcessor:
    """å‹å®‰å…¨ãªãƒ¬ã‚¹ãƒãƒ³ã‚¹å‡¦ç†ã‚¯ãƒ©ã‚¹"""

    @staticmethod
    def extract_content(response: OpenAIResponse) -> str:
        """ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æŠ½å‡º"""
        try:
            if hasattr(response, 'output_text') and response.output_text:
                return response.output_text
            elif hasattr(response, 'output') and response.output:
                content_parts = []
                for item in response.output:
                    if hasattr(item, 'content'):
                        for content in item.content:
                            if hasattr(content, 'text'):
                                content_parts.append(content.text)
                            elif hasattr(content, 'type') and content.type == "output_text":
                                if hasattr(content, 'text'):
                                    content_parts.append(content.text)
                return "\n".join(content_parts)
            else:
                return str(response)
        except Exception as e:
            print(f"Content extraction error: {e}")
            return str(response)

    @staticmethod
    def extract_tool_calls(response: OpenAIResponse) -> List[Dict[str, Any]]:
        """ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—æƒ…å ±ã‚’æŠ½å‡º"""
        tool_calls = []
        try:
            if hasattr(response, 'output') and response.output:
                for item in response.output:
                    if hasattr(item, 'type'):
                        if item.type == "mcp_tool_call":
                            tool_calls.append({
                                "type"        : "mcp",
                                "server_label": getattr(item, 'server_label', 'unknown'),
                                "tool_name"   : getattr(item, 'tool_name', 'unknown'),
                                "status"      : getattr(item, 'status', 'unknown')
                            })
                        elif item.type == "web_search_call":
                            tool_calls.append({
                                "type"  : "web_search",
                                "status": getattr(item, 'status', 'unknown')
                            })
                        elif item.type == "code_interpreter_call":
                            tool_calls.append({
                                "type"  : "code_interpreter",
                                "status": getattr(item, 'status', 'unknown')
                            })
        except Exception as e:
            print(f"Tool call extraction error: {e}")

        return tool_calls

    @staticmethod
    def get_usage_info(response: OpenAIResponse) -> Dict[str, Any]:
        """ä½¿ç”¨æƒ…å ±ã‚’å–å¾—"""
        usage_info = {}
        try:
            if hasattr(response, 'usage'):
                usage_info = {
                    "input_tokens" : getattr(response.usage, 'input_tokens', 0),
                    "output_tokens": getattr(response.usage, 'output_tokens', 0),
                    "total_tokens" : getattr(response.usage, 'total_tokens', 0)
                }

            if hasattr(response, 'model'):
                usage_info["model"] = response.model

        except Exception as e:
            print(f"Usage info extraction error: {e}")

        return usage_info


# ================================================
# è¨­å®šã¨ç’°å¢ƒç®¡ç†ï¼ˆå‹å®‰å…¨ç‰ˆï¼‰
# ================================================

class EnvironmentManager:
    """ç’°å¢ƒè¨­å®šç®¡ç†ã‚¯ãƒ©ã‚¹"""

    REQUIRED_ENV_VARS = ["OPENAI_API_KEY"]
    OPTIONAL_ENV_VARS = [
        "GITHUB_TOKEN",
        "SLACK_BOT_TOKEN",
        "GOOGLE_DRIVE_TOKEN",
        "DB_API_KEY"
    ]

    @classmethod
    def check_environment(cls) -> Dict[str, Any]:
        """ç’°å¢ƒè¨­å®šã‚’ãƒã‚§ãƒƒã‚¯"""
        status = {
            "required": {},
            "optional": {},
            "issues"  : [],
            "ready"   : True
        }

        # å¿…é ˆç’°å¢ƒå¤‰æ•°ã®ãƒã‚§ãƒƒã‚¯
        for var in cls.REQUIRED_ENV_VARS:
            is_set = bool(os.getenv(var))
            status["required"][var] = is_set
            if not is_set:
                status["issues"].append(f"Required: {var} not set")
                status["ready"] = False

        # ã‚ªãƒ—ã‚·ãƒ§ãƒ³ç’°å¢ƒå¤‰æ•°ã®ãƒã‚§ãƒƒã‚¯
        for var in cls.OPTIONAL_ENV_VARS:
            is_set = bool(os.getenv(var))
            status["optional"][var] = is_set
            if not is_set:
                status["issues"].append(f"Optional: {var} not set")

        return status

    @classmethod
    def print_environment_status(cls):
        """ç’°å¢ƒè¨­å®šçŠ¶æ³ã‚’è¡¨ç¤º"""
        status = cls.check_environment()

        print("=== Environment Status ===")
        print(f"Overall Ready: {'âœ…' if status['ready'] else 'âŒ'}")
        print()

        print("Required Environment Variables:")
        for var, is_set in status["required"].items():
            icon = "âœ…" if is_set else "âŒ"
            print(f"  {icon} {var}")

        print("\nOptional Environment Variables:")
        for var, is_set in status["optional"].items():
            icon = "âœ…" if is_set else "âš ï¸"
            print(f"  {icon} {var}")

        if status["issues"]:
            print(f"\nIssues ({len(status['issues'])}):")
            for issue in status["issues"]:
                print(f"  - {issue}")

        print(f"\nType Support: {'âœ…' if TYPES_AVAILABLE else 'âš ï¸'}")
        print(f"Pydantic Support: {'âœ…' if PYDANTIC_AVAILABLE else 'âš ï¸'}")


# ================================================
# ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°
# ================================================

async def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("=== OpenAI API + MCP å®Œå…¨å‹å¯¾å¿œç‰ˆ ===\n")

    # ç’°å¢ƒãƒã‚§ãƒƒã‚¯
    EnvironmentManager.print_environment_status()

    # ãƒ‡ãƒ¢ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®åˆæœŸåŒ–
    manager = TypedDemoManager()

    print(f"\n=== Available Demos ({len(manager.list_demos())}) ===")
    for demo_name in manager.list_demos():
        print(f"  - {demo_name}")

    # ç’°å¢ƒãŒæ•´ã£ã¦ã„ã‚‹å ´åˆã®ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    env_status = EnvironmentManager.check_environment()
    if env_status["ready"]:
        print("\n=== Running Test Demo ===")
        try:
            # éåŒæœŸãƒ‡ãƒ¢ã®ãƒ†ã‚¹ãƒˆ
            # result = await manager.run_demo_async("github_mcp")
            # processor = TypedResponseProcessor()
            # content = processor.extract_content(result)
            # tool_calls = processor.extract_tool_calls(result)
            # usage = processor.get_usage_info(result)

            # print(f"Response Content: {content[:200]}...")
            # print(f"Tool Calls: {len(tool_calls)}")
            # print(f"Usage: {usage}")

            print("Test demo ready to run (uncomment to execute)")

        except Exception as e:
            print(f"Test demo error: {e}")
    else:
        print("\nâš ï¸ Environment not ready for execution")


def run_sync_demo(demo_name: str = "github_mcp"):
    """åŒæœŸãƒ‡ãƒ¢ã®å®Ÿè¡Œ"""
    print(f"=== Running Sync Demo: {demo_name} ===")

    manager = TypedDemoManager()
    processor = TypedResponseProcessor()

    try:
        result = manager.run_demo_sync(demo_name)
        content = processor.extract_content(result)
        tool_calls = processor.extract_tool_calls(result)
        usage = processor.get_usage_info(result)

        print(f"âœ… Demo completed successfully")
        print(f"Content length: {len(content)}")
        print(f"Tool calls: {len(tool_calls)}")
        print(f"Usage: {usage}")

        return result

    except Exception as e:
        print(f"âŒ Demo failed: {e}")
        return None


async def run_async_demo(demo_name: str = "multi_mcp"):
    """éåŒæœŸãƒ‡ãƒ¢ã®å®Ÿè¡Œ"""
    print(f"=== Running Async Demo: {demo_name} ===")

    manager = TypedDemoManager()
    processor = TypedResponseProcessor()

    try:
        result = await manager.run_demo_async(demo_name)
        content = processor.extract_content(result)
        tool_calls = processor.extract_tool_calls(result)
        usage = processor.get_usage_info(result)

        print(f"âœ… Async demo completed successfully")
        print(f"Content length: {len(content)}")
        print(f"Tool calls: {len(tool_calls)}")
        print(f"Usage: {usage}")

        return result

    except Exception as e:
        print(f"âŒ Async demo failed: {e}")
        return None


async def run_streaming_demo():
    """ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ‡ãƒ¢ã®å®Ÿè¡Œ"""
    print("=== Running Streaming Demo ===")

    manager = TypedDemoManager()

    try:
        result = await manager.run_streaming_demo("streaming")
        print(f"\nâœ… Streaming completed. Total length: {len(result)}")
        return result

    except Exception as e:
        print(f"âŒ Streaming demo failed: {e}")
        return None


# ================================================
# ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¢ã®è¿½åŠ ä¾‹
# ================================================

class CustomTypedDemo(BaseTypedDemo):
    """ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¢ã®å®Ÿè£…ä¾‹"""

    def __init__(self):
        super().__init__("Custom Typed Demo")

    def create_tools(self) -> List[Union[ResponseTool, Dict[str, Any]]]:
        """ã‚«ã‚¹ã‚¿ãƒ ãƒ„ãƒ¼ãƒ«ã‚’ä½œæˆ"""
        # ä¾‹ï¼šç‹¬è‡ªã®MCPã‚µãƒ¼ãƒãƒ¼è¨­å®š
        custom_config = MCPServerConfig(
            server_url="https://my-custom-mcp.example.com",
            server_label="custom",
            headers={"Authorization": f"Bearer {os.getenv('CUSTOM_API_KEY')}"},
            allowed_tools=["custom_function_1", "custom_function_2"],
            require_approval="never"
        )

        return [
            self.tool_factory.create_mcp_tool(custom_config),
            self.tool_factory.create_code_interpreter_tool()
        ]

    def get_input_message(self) -> str:
        return "Execute custom analysis using our proprietary MCP server and code interpreter."


# ================================================
# å®Ÿè¡Œéƒ¨åˆ†
# ================================================

if __name__ == "__main__":
    # åŸºæœ¬çš„ãªç’°å¢ƒãƒã‚§ãƒƒã‚¯ã¨ãƒ‡ãƒ¢ãƒªã‚¹ãƒˆè¡¨ç¤º
    asyncio.run(main())

    print("\n=== Usage Examples ===")
    print("Sync demo:")
    print("  result = run_sync_demo('github_mcp')")
    print()
    print("Async demo:")
    print("  result = await run_async_demo('multi_mcp')")
    print()
    print("Streaming demo:")
    print("  result = await run_streaming_demo()")
    print()
    print("Custom demo:")
    print("  manager = TypedDemoManager()")
    print("  manager.add_demo('custom', CustomTypedDemo())")
    print("  result = manager.run_demo_sync('custom')")

"""
=== å®Œå…¨å‹å¯¾å¿œç‰ˆã®ç‰¹å¾´ ===

1. å®Œå…¨ãªå‹å®‰å…¨æ€§:
   - ã™ã¹ã¦ã®ãƒ„ãƒ¼ãƒ«ã§é©åˆ‡ãªå‹ä»˜ãã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½¿ç”¨
   - OpenAI Python SDKã®æ­£å¼ãªå‹å®šç¾©ã‚’æ´»ç”¨
   - Pydanticã«ã‚ˆã‚‹ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼

2. åŒ…æ‹¬çš„ãªãƒ„ãƒ¼ãƒ«å¯¾å¿œ:
   - MCPTool: MCP ã‚µãƒ¼ãƒãƒ¼ç”¨
   - CodeInterpreterTool: ã‚³ãƒ¼ãƒ‰å®Ÿè¡Œç”¨
   - WebSearchPreviewTool: Webæ¤œç´¢ç”¨
   - ImageGenerationTool: ç”»åƒç”Ÿæˆç”¨

3. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°:
   - å‹ãŒåˆ©ç”¨ã§ããªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè£…
   - ç’°å¢ƒè¨­å®šã®è‡ªå‹•ãƒã‚§ãƒƒã‚¯
   - è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±

4. æŸ”è»Ÿæ€§:
   - åŒæœŸãƒ»éåŒæœŸä¸¡å¯¾å¿œ
   - ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¯¾å¿œ
   - ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¢ã®ç°¡å˜è¿½åŠ 

5. å®Ÿç”¨æ€§:
   - ãƒ¬ã‚¹ãƒãƒ³ã‚¹å‡¦ç†ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
   - ä½¿ç”¨é‡æƒ…å ±ã®æŠ½å‡º
   - ãƒ‡ãƒãƒƒã‚°æ”¯æ´æ©Ÿèƒ½

ã“ã®å®Ÿè£…ã«ã‚ˆã‚Šã€å‹ã‚¨ãƒ©ãƒ¼ãŒå®Œå…¨ã«è§£æ±ºã•ã‚Œã€
æœ€æ–°ã®OpenAI Python SDKã§å®‰å…¨ã‹ã¤åŠ¹ç‡çš„ã«
MCPã‚µãƒ¼ãƒãƒ¼ã‚’åˆ©ç”¨ã§ãã¾ã™ã€‚
"""