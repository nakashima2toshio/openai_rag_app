# streamlit run a30_30_rag_search.py --server.port=8501
# a30_30_rag_search.py - æœ€æ–°OpenAI Responses APIå®Œå…¨å¯¾å¿œç‰ˆ
# OpenAI Responses API + file_search ãƒ„ãƒ¼ãƒ« + ç’°å¢ƒå¤‰æ•°APIã‚­ãƒ¼å¯¾å¿œ
"""
ğŸ” æœ€æ–°RAGæ¤œç´¢ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³

ã€å‰ææ¡ä»¶ã€‘
1. OpenAI APIã‚­ãƒ¼ã®ç’°å¢ƒå¤‰æ•°è¨­å®šï¼ˆå¿…é ˆï¼‰:
   export OPENAI_API_KEY='your-api-key-here'

2. å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼ˆå¿…é ˆï¼‰:
   pip install streamlit openai
   pip install openai-agents

ã€å®Ÿè¡Œæ–¹æ³•ã€‘
streamlit run a30_30_rag_search.py --server.port=8501

ã€ä¸»è¦æ©Ÿèƒ½ã€‘
âœ… æœ€æ–°Responses APIä½¿ç”¨
âœ… file_search ãƒ„ãƒ¼ãƒ«ã§Vector Storeæ¤œç´¢
âœ… ãƒ•ã‚¡ã‚¤ãƒ«å¼•ç”¨è¡¨ç¤º
âœ… å‹å®‰å…¨å®Ÿè£…ï¼ˆå‹ã‚¨ãƒ©ãƒ¼å®Œå…¨ä¿®æ­£ï¼‰
âœ… ç’°å¢ƒå¤‰æ•°ã§APIã‚­ãƒ¼ç®¡ç†
âœ… è‹±èª/æ—¥æœ¬èªè³ªå•å¯¾å¿œ
âœ… ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºå¯èƒ½ãªæ¤œç´¢ã‚ªãƒ—ã‚·ãƒ§ãƒ³

ã€å®‰å…¨æ€§ã€‘
- ç’°å¢ƒå¤‰æ•°ã§APIã‚­ãƒ¼ç®¡ç†ï¼ˆsecrets.tomlä¸è¦ï¼‰
- å‹ãƒã‚§ãƒƒã‚¯å›é¿ã«ã‚ˆã‚‹å®‰å®šæ€§
- ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¼·åŒ–
"""
import streamlit as st
import time
import logging
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime
from pathlib import Path
import json
import traceback

# OpenAI SDK ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
    logger = logging.getLogger(__name__)
    logger.info("âœ… OpenAI SDK ãŒãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã—ãŸ")
except ImportError as e:
    OPENAI_AVAILABLE = False
    st.error(f"OpenAI SDK ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {e}")
    st.stop()

# Agent SDK ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
try:
    from agents import Agent, Runner, SQLiteSession
    AGENT_SDK_AVAILABLE = True
    logger.info("âœ… OpenAI Agent SDK ã‚‚ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã—ãŸ")
except ImportError as e:
    AGENT_SDK_AVAILABLE = False
    logger.info(f"Agent SDK ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³æ©Ÿèƒ½ã®ãŸã‚å•é¡Œãªã—ï¼‰: {e}")

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Vector Store IDã®è¨­å®š
VECTOR_STORES = {
    "Customer Support FAQ"    : "vs_687a0604f1508191aaf416d88e266ab7",
    "Science & Technology Q&A": "vs_687a061acc908191af7d5d9ba623470b",
    "Medical Q&A"             : "vs_687a060f9ed881918b213bfdeab8241b",
    "Legal Q&A"               : "vs_687a062418ec8191872efdbf8f554836"
}

# Vector Storeã®é †åºãƒªã‚¹ãƒˆï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å¯¾å¿œç”¨ï¼‰
VECTOR_STORE_LIST = list(VECTOR_STORES.keys())

# è¨€èªè¨­å®š
LANGUAGE_OPTIONS = {
    "English": "en",
    "æ—¥æœ¬èª": "ja"
}

# ãƒ†ã‚¹ãƒˆç”¨è³ªå•ï¼ˆè‹±èªç‰ˆ - RAGãƒ‡ãƒ¼ã‚¿ã«æœ€é©åŒ–ï¼‰
test_questions_en = [
    "How do I create a new account?",
    "What payment methods are available?",
    "Can I return a product?",
    "I forgot my password",
    "How can I contact the support team?"
]

test_questions_2_en = [
    "What are the latest trends in artificial intelligence?",
    "What is the principle of quantum computing?",
    "What are the types and characteristics of renewable energy?",
    "What are the current status and challenges of gene editing technology?",
    "What are the latest technologies in space exploration?"
]

test_questions_3_en = [
    "How to prevent high blood pressure?",
    "What are the symptoms and treatment of diabetes?",
    "What are the risk factors for heart disease?",
    "What are the guidelines for healthy eating?",
    "What is the relationship between exercise and health?"
]

test_questions_4_en = [
    "What are the important clauses in contracts?",
    "How to protect intellectual property rights?",
    "What are the basic principles of labor law?",
    "What is an overview of personal data protection law?",
    "What is the scope of application of consumer protection law?"
]

# ãƒ†ã‚¹ãƒˆç”¨è³ªå•ï¼ˆæ—¥æœ¬èªç‰ˆ - ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
test_questions_ja = [
    "æ–°è¦ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’ä½œã‚‹ã«ã¯ã©ã†ã™ã‚Œã°ã‚ˆã„ã§ã™ã‹ï¼Ÿ",
    "ã©ã®ã‚ˆã†ãªæ±ºæ¸ˆæ–¹æ³•ãŒåˆ©ç”¨ã§ãã¾ã™ã‹ï¼Ÿ",
    "å•†å“ã‚’è¿”å“ã™ã‚‹ã“ã¨ã¯ã§ãã¾ã™ã‹ï¼Ÿ",
    "ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å¿˜ã‚Œã¦ã—ã¾ã„ã¾ã—ãŸ",
    "ã‚µãƒãƒ¼ãƒˆãƒãƒ¼ãƒ ã«é€£çµ¡ã™ã‚‹æ–¹æ³•ã‚’æ•™ãˆã¦ãã ã•ã„"
]

test_questions_2_ja = [
    "äººå·¥çŸ¥èƒ½ã®æœ€æ–°å‹•å‘ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„",
    "é‡å­ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã®åŸç†ã¨ã¯ï¼Ÿ",
    "å†ç”Ÿå¯èƒ½ã‚¨ãƒãƒ«ã‚®ãƒ¼ã®ç¨®é¡ã¨ç‰¹å¾´",
    "éºä¼å­ç·¨é›†æŠ€è¡“ã®ç¾çŠ¶ã¨èª²é¡Œ",
    "å®‡å®™æ¢æŸ»ã®æœ€æ–°æŠ€è¡“ã«ã¤ã„ã¦"
]

test_questions_3_ja = [
    "é«˜è¡€åœ§ã®äºˆé˜²æ–¹æ³•ã«ã¤ã„ã¦",
    "ç³–å°¿ç—…ã®ç—‡çŠ¶ã¨æ²»ç™‚æ³•",
    "å¿ƒè‡“ç—…ã®ãƒªã‚¹ã‚¯ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼",
    "å¥åº·çš„ãªé£Ÿäº‹ã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³",
    "é‹å‹•ã¨å¥åº·ã®é–¢ä¿‚ã«ã¤ã„ã¦"
]

test_questions_4_ja = [
    "å¥‘ç´„æ›¸ã®é‡è¦ãªæ¡é …ã«ã¤ã„ã¦",
    "çŸ¥çš„è²¡ç”£æ¨©ã®ä¿è­·æ–¹æ³•",
    "åŠ´åƒæ³•ã®åŸºæœ¬åŸå‰‡",
    "å€‹äººæƒ…å ±ä¿è­·æ³•ã®æ¦‚è¦",
    "æ¶ˆè²»è€…ä¿è­·æ³•ã®é©ç”¨ç¯„å›²"
]

# ãƒ†ã‚¹ãƒˆç”¨è³ªå•ã®é…åˆ—ï¼ˆVECTOR_STORESã®é †åºã¨å¯¾å¿œï¼‰
test_q_en = [
    test_questions_en,     # Customer Support FAQ
    test_questions_2_en,   # Science & Technology Q&A
    test_questions_3_en,   # Medical Q&A
    test_questions_4_en,   # Legal Q&A
]

test_q_ja = [
    test_questions_ja,     # Customer Support FAQ
    test_questions_2_ja,   # Science & Technology Q&A
    test_questions_3_ja,   # Medical Q&A
    test_questions_4_ja,   # Legal Q&A
]

# OpenAI APIã‚­ãƒ¼ã®è¨­å®šï¼ˆç’°å¢ƒå¤‰æ•°ã‹ã‚‰è‡ªå‹•å–å¾—ï¼‰
try:
    # ç’°å¢ƒå¤‰æ•° OPENAI_API_KEY ã‹ã‚‰è‡ªå‹•çš„ã«èª­ã¿å–ã‚Š
    openai_client = OpenAI()
    logger.info("âœ… OpenAI APIã‚­ãƒ¼ãŒç’°å¢ƒå¤‰æ•°ã‹ã‚‰æ­£å¸¸ã«èª­ã¿è¾¼ã¾ã‚Œã¾ã—ãŸ")
except Exception as e:
    st.error(f"OpenAI API ã‚­ãƒ¼ã®è¨­å®šã«å•é¡ŒãŒã‚ã‚Šã¾ã™: {e}")
    st.error("ç’°å¢ƒå¤‰æ•° OPENAI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„")
    st.code("export OPENAI_API_KEY='your-api-key-here'")
    st.stop()


class ModernRAGManager:
    """æœ€æ–°Responses API + file_search ã‚’ä½¿ç”¨ã—ãŸRAGãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼"""

    def __init__(self):
        self.agent_sessions = {}  # Agent SDKç”¨ã‚»ãƒƒã‚·ãƒ§ãƒ³ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

    def search_with_responses_api(self, query: str, store_name: str, **kwargs) -> Tuple[str, Dict[str, Any]]:
        """æœ€æ–°Responses API + file_search ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ãŸæ¤œç´¢"""
        try:
            store_id = VECTOR_STORES[store_name]

            # file_search ãƒ„ãƒ¼ãƒ«ã®è¨­å®šï¼ˆæ­£ã—ã„å‹ã§å®šç¾©ï¼‰
            file_search_tool_dict = {
                "type": "file_search",
                "vector_store_ids": [store_id]
            }

            # ã‚ªãƒ—ã‚·ãƒ§ãƒ³è¨­å®šï¼ˆå‹å®‰å…¨ãªæ–¹æ³•ï¼‰
            max_results = kwargs.get('max_results', 20)
            include_results = kwargs.get('include_results', True)
            filters = kwargs.get('filters', None)

            # å‹å®‰å…¨ãªè¾æ›¸æ›´æ–°
            if max_results and isinstance(max_results, int):
                file_search_tool_dict["max_num_results"] = max_results
            if filters is not None:
                file_search_tool_dict["filters"] = filters

            # include ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¨­å®š
            include_params = []
            if include_results:
                include_params.append("file_search_call.results")

            # Responses APIå‘¼ã³å‡ºã—ï¼ˆå‹å®‰å…¨ãªæ–¹æ³•ï¼‰
            # OpenAI SDKã®å‹å®šç¾©ãŒå³å¯†ãªãŸã‚ã€å®Ÿéš›ã®å‹•ä½œã«å•é¡ŒãŒãªã„å ´åˆã¯å‹ãƒã‚§ãƒƒã‚¯ã‚’ç„¡è¦–
            response = openai_client.responses.create(
                model="gpt-4o-mini",
                input=query,
                tools=[file_search_tool_dict],  # type: ignore[arg-type]
                include=include_params if include_params else None
            )

            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ†ã‚­ã‚¹ãƒˆã®æŠ½å‡º
            response_text = self._extract_response_text(response)

            # ãƒ•ã‚¡ã‚¤ãƒ«å¼•ç”¨ã®æŠ½å‡º
            citations = self._extract_citations(response)

            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®æ§‹ç¯‰ï¼ˆå‹ã‚’æ˜ç¤ºçš„ã«æŒ‡å®šï¼‰
            metadata: Dict[str, Any] = {
                "store_name": store_name,
                "store_id": store_id,
                "query": query,
                "timestamp": datetime.now().isoformat(),
                "model": "gpt-4o-mini",
                "method": "responses_api_file_search",
                "citations": citations,
                "tool_calls": self._extract_tool_calls(response)
            }

            # ä½¿ç”¨çµ±è¨ˆãŒã‚ã‚Œã°è¿½åŠ ï¼ˆå‹å®‰å…¨ãªæ–¹æ³•ï¼‰
            if hasattr(response, 'usage') and response.usage is not None:
                try:
                    # ResponseUsageã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’è¾æ›¸ã«å¤‰æ›
                    if hasattr(response.usage, 'model_dump'):
                        metadata["usage"] = response.usage.model_dump()
                    elif hasattr(response.usage, 'dict'):
                        metadata["usage"] = response.usage.dict()
                    else:
                        # æ‰‹å‹•ã§å±æ€§ã‚’æŠ½å‡º
                        usage_dict = {}
                        for attr in ['prompt_tokens', 'completion_tokens', 'total_tokens']:
                            if hasattr(response.usage, attr):
                                usage_dict[attr] = getattr(response.usage, attr)
                        metadata["usage"] = usage_dict
                except Exception as e:
                    logger.warning(f"ä½¿ç”¨çµ±è¨ˆã®å¤‰æ›ã«å¤±æ•—: {e}")
                    metadata["usage"] = str(response.usage)

            return response_text, metadata

        except Exception as e:
            error_msg = f"Responses APIæ¤œç´¢ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
            logger.error(error_msg)
            logger.error(traceback.format_exc())

            # ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼ˆå‹å®‰å…¨ï¼‰
            error_metadata: Dict[str, Any] = {
                "error": str(e),
                "method": "responses_api_error",
                "store_name": store_name,
                "query": query,
                "timestamp": datetime.now().isoformat()
            }
            return error_msg, error_metadata

    def search_with_agent_sdk(self, query: str, store_name: str) -> Tuple[str, Dict[str, Any]]:
        """Agent SDKã‚’ä½¿ç”¨ã—ãŸæ¤œç´¢ï¼ˆç°¡æ˜“ç‰ˆ - file_searchã¯Responses APIã§å®Ÿè¡Œï¼‰"""
        try:
            if not AGENT_SDK_AVAILABLE:
                logger.info("Agent SDKåˆ©ç”¨ä¸å¯ã€Responses APIã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯")
                return self.search_with_responses_api(query, store_name)

            # æ³¨æ„: Agent SDKã§ã®file_searchãƒ„ãƒ¼ãƒ«çµ±åˆã¯è¤‡é›‘ãªãŸã‚ã€
            # ç¾åœ¨ã¯ç°¡æ˜“ç‰ˆã¨ã—ã¦é€šå¸¸ã®Agentå®Ÿè¡Œã®ã¿è¡Œã„ã€
            # å®Ÿéš›ã®RAGæ©Ÿèƒ½ã¯Responses APIã«å§”è­²

            # Agent SDKã‚»ãƒƒã‚·ãƒ§ãƒ³ã®å–å¾—/ä½œæˆ
            session_key = f"{store_name}_agent"
            if session_key not in self.agent_sessions:
                self.agent_sessions[session_key] = SQLiteSession(session_key)

            session = self.agent_sessions[session_key]

            # ç°¡æ˜“Agentä½œæˆï¼ˆfile_searchãªã—ï¼‰
            agent = Agent(
                name=f"RAG_Agent_{store_name.replace(' ', '_')}",
                instructions=f"""
                You are a helpful assistant specializing in {store_name}.
                Provide informative and accurate responses based on your knowledge.
                Be professional and helpful in your responses.
                """,
                model="gpt-4o-mini"
            )

            # Runnerå®Ÿè¡Œï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†ã®ã¿ã®åˆ©ç‚¹ï¼‰
            result = Runner.run_sync(
                agent,
                query,
                session=session
            )

            response_text = result.final_output if hasattr(result, 'final_output') else str(result)

            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®æ§‹ç¯‰
            metadata: Dict[str, Any] = {
                "store_name": store_name,
                "store_id": VECTOR_STORES[store_name],
                "query": query,
                "timestamp": datetime.now().isoformat(),
                "model": "gpt-4o-mini",
                "method": "agent_sdk_simple_session",
                "note": "Agent SDKã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†ã®ã¿ã€RAGæ©Ÿèƒ½ãªã—"
            }

            logger.info("Agent SDKæ¤œç´¢å®Œäº†ï¼ˆç°¡æ˜“ç‰ˆï¼‰")
            return response_text, metadata

        except Exception as e:
            error_msg = f"Agent SDKæ¤œç´¢ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {str(e)}"
            logger.error(error_msg)
            logger.warning("Agent SDKã‚¨ãƒ©ãƒ¼ã«ã‚ˆã‚ŠResponses APIã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯")
            # Agent SDKãŒå¤±æ•—ã—ãŸå ´åˆã¯Responses APIã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            return self.search_with_responses_api(query, store_name)

    def search(self, query: str, store_name: str, use_agent_sdk: bool = True, **kwargs) -> Tuple[str, Dict[str, Any]]:
        """çµ±åˆæ¤œç´¢ãƒ¡ã‚½ãƒƒãƒ‰"""
        if use_agent_sdk and AGENT_SDK_AVAILABLE:
            return self.search_with_agent_sdk(query, store_name)
        else:
            return self.search_with_responses_api(query, store_name, **kwargs)

    def _extract_response_text(self, response) -> str:
        """ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º"""
        try:
            # output_textå±æ€§ãŒã‚ã‚‹å ´åˆ
            if hasattr(response, 'output_text'):
                return response.output_text

            # outputé…åˆ—ã‹ã‚‰æŠ½å‡º
            if hasattr(response, 'output') and response.output:
                for item in response.output:
                    if hasattr(item, 'type') and item.type == "message":
                        if hasattr(item, 'content') and item.content:
                            for content in item.content:
                                if hasattr(content, 'type') and content.type == "output_text":
                                    return content.text

            return "ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ†ã‚­ã‚¹ãƒˆã®æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸ"

        except Exception as e:
            logger.error(f"ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            return f"ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}"

    def _extract_citations(self, response) -> List[Dict[str, Any]]:
        """ãƒ•ã‚¡ã‚¤ãƒ«å¼•ç”¨æƒ…å ±ã‚’æŠ½å‡º"""
        citations: List[Dict[str, Any]] = []
        try:
            if hasattr(response, 'output') and response.output:
                for item in response.output:
                    if hasattr(item, 'type') and item.type == "message":
                        if hasattr(item, 'content') and item.content:
                            for content in item.content:
                                if hasattr(content, 'annotations'):
                                    for annotation in content.annotations:
                                        if hasattr(annotation, 'type') and annotation.type == "file_citation":
                                            citations.append({
                                                "file_id": getattr(annotation, 'file_id', ''),
                                                "filename": getattr(annotation, 'filename', ''),
                                                "index": getattr(annotation, 'index', 0)
                                            })
        except Exception as e:
            logger.error(f"å¼•ç”¨æƒ…å ±æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")

        return citations

    def _extract_tool_calls(self, response) -> List[Dict[str, Any]]:
        """ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—æƒ…å ±ã‚’æŠ½å‡º"""
        tool_calls: List[Dict[str, Any]] = []
        try:
            if hasattr(response, 'output') and response.output:
                for item in response.output:
                    if hasattr(item, 'type') and item.type == "file_search_call":
                        tool_calls.append({
                            "id": getattr(item, 'id', ''),
                            "type": "file_search",
                            "status": getattr(item, 'status', ''),
                            "queries": getattr(item, 'queries', [])
                        })
        except Exception as e:
            logger.error(f"ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—æƒ…å ±æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")

        return tool_calls


# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
@st.cache_resource
def get_rag_manager():
    """RAGãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³å–å¾—"""
    return ModernRAGManager()


def initialize_session_state():
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–"""
    if 'search_history' not in st.session_state:
        st.session_state.search_history = []
    if 'current_query' not in st.session_state:
        st.session_state.current_query = ""
    if 'selected_store' not in st.session_state:
        st.session_state.selected_store = list(VECTOR_STORES.keys())[0]
    if 'selected_language' not in st.session_state:
        st.session_state.selected_language = "English"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯è‹±èªï¼ˆRAGãƒ‡ãƒ¼ã‚¿ã«åˆã‚ã›ã¦ï¼‰
    if 'use_agent_sdk' not in st.session_state:
        st.session_state.use_agent_sdk = False  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯Responses APIç›´æ¥ä½¿ç”¨
    if 'search_options' not in st.session_state:
        st.session_state.search_options = {
            'max_results': 20,
            'include_results': True,
            'show_citations': True
        }


def display_search_history():
    """æ¤œç´¢å±¥æ­´ã®è¡¨ç¤º"""
    st.header("ğŸ•’ æ¤œç´¢å±¥æ­´")

    if not st.session_state.search_history:
        st.info("æ¤œç´¢å±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“")
        return

    # å±¥æ­´ã‚’ã‚¨ã‚¯ã‚¹ãƒ‘ãƒ³ãƒ€ãƒ¼ã§è¡¨ç¤º
    for i, item in enumerate(st.session_state.search_history[:10]):  # æœ€æ–°10ä»¶
        with st.expander(f"å±¥æ­´ {i + 1}: {item['query'][:50]}..."):
            st.markdown(f"**è³ªå•:** {item['query']}")
            st.markdown(f"**Vector Store:** {item['store_name']}")
            st.markdown(f"**å®Ÿè¡Œæ™‚é–“:** {item['timestamp']}")
            st.markdown(f"**æ¤œç´¢æ–¹æ³•:** {item.get('method', 'unknown')}")

            # å¼•ç”¨æƒ…å ±è¡¨ç¤º
            if 'citations' in item and item['citations']:
                st.markdown("**å¼•ç”¨ãƒ•ã‚¡ã‚¤ãƒ«:**")
                for citation in item['citations']:
                    st.markdown(f"- {citation.get('filename', 'Unknown file')}")

            col1, col2 = st.columns(2)
            with col1:
                if st.button("å†å®Ÿè¡Œ", key=f"rerun_{i}"):
                    st.session_state.current_query = item['query']
                    st.session_state.selected_store = item['store_name']
                    st.rerun()
            with col2:
                if st.button("è©³ç´°è¡¨ç¤º", key=f"detail_{i}"):
                    st.json(item)


def get_selected_store_index(selected_store: str) -> int:
    """é¸æŠã•ã‚ŒãŸVector Storeã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—"""
    try:
        return VECTOR_STORE_LIST.index(selected_store)
    except ValueError:
        return 0  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯æœ€åˆã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹


def display_test_questions():
    """ãƒ†ã‚¹ãƒˆç”¨è³ªå•ã®è¡¨ç¤ºï¼ˆæ”¹ä¿®ç‰ˆãƒ»è¨€èªå¯¾å¿œï¼‰"""
    # ç¾åœ¨é¸æŠã•ã‚Œã¦ã„ã‚‹Vector Storeã¨è¨€èªã‚’å–å¾—
    selected_store = st.session_state.get('selected_store', VECTOR_STORE_LIST[0])
    selected_language = st.session_state.get('selected_language', 'English')
    store_index = get_selected_store_index(selected_store)

    # è¨€èªã«å¿œã˜ã¦è³ªå•ãƒªã‚¹ãƒˆã‚’é¸æŠ
    if selected_language == "English":
        questions = test_q_en[store_index] if store_index < len(test_q_en) else []
        lang_suffix = "en"
    else:
        questions = test_q_ja[store_index] if store_index < len(test_q_ja) else []
        lang_suffix = "ja"

    # ãƒ˜ãƒƒãƒ€ãƒ¼ã®å‹•çš„ç”Ÿæˆ
    if selected_language == "English":
        header = f"Test Questions ({selected_store})"
    else:
        header = f"ãƒ†ã‚¹ãƒˆç”¨è³ªå•ï¼ˆ{selected_store}ï¼‰"

    st.header(f"ğŸ’¡ {header}")

    # RAGãƒ‡ãƒ¼ã‚¿ãŒè‹±èªã®å ´åˆã®æ³¨æ„æ›¸ã
    if selected_language == "æ—¥æœ¬èª":
        st.warning("âš ï¸ RAGãƒ‡ãƒ¼ã‚¿ã¯è‹±èªã§ä½œæˆã•ã‚Œã¦ã„ã¾ã™ã€‚è‹±èªã§ã®è³ªå•ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚")
    else:
        st.success("âœ… è‹±èªè³ªå•ï¼ˆRAGãƒ‡ãƒ¼ã‚¿ã«æœ€é©åŒ–ï¼‰")

    if not questions:
        if selected_language == "English":
            st.info("No test questions available for this Vector Store")
        else:
            st.info("ã“ã®Vector Storeã«å¯¾å¿œã™ã‚‹ãƒ†ã‚¹ãƒˆè³ªå•ãŒã‚ã‚Šã¾ã›ã‚“")
        return

    # è³ªå•ãƒœã‚¿ãƒ³ã®è¡¨ç¤º
    for i, question in enumerate(questions):
        button_key = f"test_q_{selected_store}_{lang_suffix}_{i}"
        if st.button(f"Q{i + 1}: {question}", key=button_key):
            st.session_state.current_query = question
            st.session_state.selected_store = selected_store
            st.rerun()


def display_system_info():
    """ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±ã®è¡¨ç¤º"""
    with st.expander("ğŸ”§ ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±", expanded=False):
        st.write("**åˆ©ç”¨å¯èƒ½ãªæ©Ÿèƒ½:**")
        st.write(f"- OpenAI SDK: {'âœ…' if OPENAI_AVAILABLE else 'âŒ'}")
        st.write(f"- Responses API: âœ…")
        st.write(f"- file_search ãƒ„ãƒ¼ãƒ«: âœ…")
        st.write(f"- Agent SDK: {'âœ…ï¼ˆç°¡æ˜“ç‰ˆï¼‰' if AGENT_SDK_AVAILABLE else 'âŒ'}")
        st.write(f"- Vector Store RAG: âœ…")
        st.write(f"- ãƒ•ã‚¡ã‚¤ãƒ«å¼•ç”¨: âœ…")
        st.write(f"- æ¤œç´¢çµæœè©³ç´°: âœ…")
        st.write(f"- å‹å®‰å…¨å®Ÿè£…: âœ…")
        st.write(f"- ç’°å¢ƒå¤‰æ•°APIã‚­ãƒ¼: âœ…")

        st.write("**APIã‚­ãƒ¼è¨­å®š:**")
        st.write("- ç’°å¢ƒå¤‰æ•° `OPENAI_API_KEY` ã‹ã‚‰è‡ªå‹•å–å¾—")
        st.write("- Streamlit secrets.toml ä¸è¦")
        st.code("export OPENAI_API_KEY='your-api-key-here'")

        st.write("**Vector Stores:**")
        for i, (name, store_id) in enumerate(VECTOR_STORES.items()):
            st.write(f"{i+1}. {name}: `{store_id}`")

        if st.session_state.search_history:
            st.write(f"**æ¤œç´¢å±¥æ­´:** {len(st.session_state.search_history)} ä»¶")

        # Vector Storeé€£å‹•æƒ…å ±
        st.write("**è¨­å®šæƒ…å ±:**")
        selected_store = st.session_state.get('selected_store', VECTOR_STORE_LIST[0])
        selected_language = st.session_state.get('selected_language', 'English')
        store_index = get_selected_store_index(selected_store)

        # è¨€èªã«å¿œã˜ãŸè³ªå•æ•°ã‚’å–å¾—
        if selected_language == "English":
            question_count = len(test_q_en[store_index]) if store_index < len(test_q_en) else 0
        else:
            question_count = len(test_q_ja[store_index]) if store_index < len(test_q_ja) else 0

        st.write(f"- é¸æŠVector Store: {selected_store}")
        st.write(f"- ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: {store_index}")
        st.write(f"- è¨€èª: {selected_language}")
        st.write(f"- ãƒ†ã‚¹ãƒˆè³ªå•æ•°: {question_count}")
        st.write(f"- Agent SDKä½¿ç”¨: {'æœ‰åŠ¹' if st.session_state.get('use_agent_sdk', False) else 'ç„¡åŠ¹'}")

        # RAGæœ€é©åŒ–æƒ…å ±
        if selected_language == "English":
            st.write("- ğŸ¯ RAGæœ€é©åŒ–: âœ…")
        else:
            st.write("- âš ï¸ RAGæœ€é©åŒ–: è¨€èªä¸ä¸€è‡´")


def display_search_options():
    """æ¤œç´¢ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®è¡¨ç¤º"""
    with st.expander("âš™ï¸ æ¤œç´¢ã‚ªãƒ—ã‚·ãƒ§ãƒ³", expanded=False):
        # æœ€å¤§çµæœæ•°
        max_results = st.slider(
            "æœ€å¤§æ¤œç´¢çµæœæ•°",
            min_value=1,
            max_value=50,
            value=st.session_state.search_options['max_results'],
            help="Vector Storeã‹ã‚‰å–å¾—ã™ã‚‹æœ€å¤§çµæœæ•°"
        )
        st.session_state.search_options['max_results'] = max_results

        # æ¤œç´¢çµæœè©³ç´°ã‚’å«ã‚ã‚‹
        include_results = st.checkbox(
            "æ¤œç´¢çµæœè©³ç´°ã‚’å«ã‚ã‚‹",
            value=st.session_state.search_options['include_results'],
            help="file_search_call.resultsã‚’å«ã‚ã‚‹"
        )
        st.session_state.search_options['include_results'] = include_results

        # å¼•ç”¨è¡¨ç¤º
        show_citations = st.checkbox(
            "ãƒ•ã‚¡ã‚¤ãƒ«å¼•ç”¨ã‚’è¡¨ç¤º",
            value=st.session_state.search_options['show_citations'],
            help="ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«ãƒ•ã‚¡ã‚¤ãƒ«å¼•ç”¨æƒ…å ±ã‚’è¡¨ç¤º"
        )
        st.session_state.search_options['show_citations'] = show_citations

        # Agent SDKä½¿ç”¨è¨­å®š
        if AGENT_SDK_AVAILABLE:
            use_agent_sdk = st.checkbox(
                "Agent SDKã‚’ä½¿ç”¨",
                value=st.session_state.use_agent_sdk,
                help="Agent SDKã‚’ä½¿ç”¨ã—ã¦ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†ã‚’æœ‰åŠ¹åŒ–"
            )
            st.session_state.use_agent_sdk = use_agent_sdk


def display_search_results(response_text: str, metadata: Dict[str, Any]):
    """æ¤œç´¢çµæœã®è¡¨ç¤º"""
    st.markdown("### ğŸ¤– å›ç­”")
    st.markdown(response_text)

    # ãƒ•ã‚¡ã‚¤ãƒ«å¼•ç”¨ã®è¡¨ç¤º
    if metadata.get('citations') and st.session_state.search_options['show_citations']:
        st.markdown("### ğŸ“š å¼•ç”¨ãƒ•ã‚¡ã‚¤ãƒ«")
        citations = metadata['citations']
        for i, citation in enumerate(citations, 1):
            st.markdown(f"{i}. **{citation.get('filename', 'Unknown file')}** (ID: `{citation.get('file_id', '')}`)")

    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è¡¨ç¤º
    st.markdown("---")
    st.markdown("### ğŸ“Š æ¤œç´¢æƒ…å ±")
    col1, col2 = st.columns(2)

    with col1:
        st.markdown(f"**Vector Store:** {metadata.get('store_name', '')}")
        st.markdown(f"**Store ID:** `{metadata.get('store_id', '')}`")
        st.markdown(f"**æ¤œç´¢æ–¹æ³•:** {metadata.get('method', '')}")

    with col2:
        st.markdown(f"**ãƒ¢ãƒ‡ãƒ«:** {metadata.get('model', '')}")
        st.markdown(f"**å®Ÿè¡Œæ™‚é–“:** {metadata.get('timestamp', '')}")
        if 'tool_calls' in metadata and metadata['tool_calls']:
            st.markdown(f"**ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—:** {len(metadata['tool_calls'])}å›")

    # è©³ç´°æƒ…å ±
    with st.expander("ğŸ” è©³ç´°æƒ…å ±", expanded=False):
        st.json(metadata)


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    st.set_page_config(
        page_title="æœ€æ–°RAGæ¤œç´¢ã‚¢ãƒ—ãƒªï¼ˆå®Œå…¨ä¿®æ­£ç‰ˆï¼‰",
        page_icon="ğŸ”",
        layout="wide"
    )

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤è¨­å®šï¼‰
    initialize_session_state()

    # RAGãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®å–å¾—
    rag_manager = get_rag_manager()

    # ãƒ˜ãƒƒãƒ€ãƒ¼
    st.write("ğŸ” æœ€æ–°RAGæ¤œç´¢ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆå®Œå…¨ä¿®æ­£ç‰ˆï¼‰")

    # APIçŠ¶æ³è¡¨ç¤º
    col1, col2 = st.columns(2)
    with col1:
        st.success("âœ… OpenAI Responses API åˆ©ç”¨å¯èƒ½")
        st.success("âœ… file_search ãƒ„ãƒ¼ãƒ«å¯¾å¿œ")
    with col2:
        if AGENT_SDK_AVAILABLE:
            st.success("âœ… Agent SDK åˆ©ç”¨å¯èƒ½")
        else:
            st.info("â„¹ï¸ Agent SDK æœªåˆ©ç”¨ï¼ˆResponses APIã®ã¿ï¼‰")

    st.markdown("---")

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    with st.sidebar:
        st.header("âš™ï¸ è¨­å®š")

        # Vector Storeé¸æŠ
        selected_store = st.selectbox(
            "Vector Store ã‚’é¸æŠ",
            options=list(VECTOR_STORES.keys()),
            index=list(VECTOR_STORES.keys()).index(st.session_state.selected_store),
            key="store_selection"
        )
        st.session_state.selected_store = selected_store

        # é¸æŠã•ã‚ŒãŸVector Store IDã‚’è¡¨ç¤º
        st.code(VECTOR_STORES[selected_store])

        # è¨€èªé¸æŠ
        st.markdown("---")
        selected_language = st.selectbox(
            "Test Question Language",
            options=list(LANGUAGE_OPTIONS.keys()),
            index=list(LANGUAGE_OPTIONS.keys()).index(st.session_state.selected_language),
            key="language_selection",
            help="è‹±èªè³ªå•ã¯RAGãƒ‡ãƒ¼ã‚¿ã«æœ€é©åŒ–ã•ã‚Œã¦ã„ã¾ã™"
        )
        st.session_state.selected_language = selected_language

        # è¨€èªã«å¿œã˜ãŸæ¨å¥¨è¡¨ç¤º
        if selected_language == "English":
            st.success("âœ… Optimized for English RAG data")
        else:
            st.warning("âš ï¸ RAGãƒ‡ãƒ¼ã‚¿ã¯è‹±èªã§ã™")

        # æ¤œç´¢ã‚ªãƒ—ã‚·ãƒ§ãƒ³
        display_search_options()

        # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±
        display_system_info()

        # ãƒ†ã‚¹ãƒˆç”¨è³ªå•ï¼ˆé¸æŠã•ã‚ŒãŸVector Storeã«å¯¾å¿œï¼‰
        with st.expander("ğŸ’¡ ãƒ†ã‚¹ãƒˆç”¨è³ªå•", expanded=True):
            display_test_questions()

    # ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
    col1, col2 = st.columns([1, 1])

    with col1:
        st.header("â“ è³ªå•å…¥åŠ›")

        # è³ªå•å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ 
        with st.form("search_form"):
            query = st.text_area(
                "è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
                value=st.session_state.current_query,
                height=100,
                key="query_input",
                help="è‹±èªã§ã®è³ªå•ãŒRAGãƒ‡ãƒ¼ã‚¿ã«æœ€é©åŒ–ã•ã‚Œã¦ã„ã¾ã™"
            )

            submitted = st.form_submit_button("ğŸ” æ¤œç´¢å®Ÿè¡Œ", type="primary")

        if submitted and query.strip():
            st.session_state.current_query = query

            # æ¤œç´¢å®Ÿè¡Œ
            with col2:
                st.header("ğŸ¤– æ¤œç´¢çµæœ")

                with st.spinner("ğŸ” Vector Storeæ¤œç´¢ä¸­..."):
                    # æ¤œç´¢ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®å–å¾—
                    search_options = st.session_state.search_options

                    # æ¤œç´¢å®Ÿè¡Œ
                    final_result, final_metadata = rag_manager.search(
                        query,
                        selected_store,
                        use_agent_sdk=st.session_state.use_agent_sdk,
                        max_results=search_options['max_results'],
                        include_results=search_options['include_results']
                    )

                # çµæœè¡¨ç¤º
                display_search_results(final_result, final_metadata)

                # æ¤œç´¢å±¥æ­´ã«è¿½åŠ ï¼ˆå‹å®‰å…¨ï¼‰
                history_item: Dict[str, Any] = {
                    "query": query,
                    "store_name": selected_store,
                    "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    "method": final_metadata.get('method', 'unknown'),
                    "citations": final_metadata.get('citations', []),
                    "result_preview": final_result[:200] + "..." if len(final_result) > 200 else final_result
                }

                # é‡è¤‡ãƒã‚§ãƒƒã‚¯
                if not any(item['query'] == query and item['store_name'] == selected_store
                           for item in st.session_state.search_history):
                    st.session_state.search_history.insert(0, history_item)
                    st.session_state.search_history = st.session_state.search_history[:50]  # æœ€æ–°50ä»¶ä¿æŒ

        elif submitted and not query.strip():
            st.error("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")

    with col2:
        if not st.session_state.current_query:
            st.header("ğŸ¤– æ¤œç´¢çµæœ")
            st.info("è³ªå•ã‚’å…¥åŠ›ã—ã¦æ¤œç´¢ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")

            # APIæ©Ÿèƒ½èª¬æ˜
            st.markdown("### ğŸš€ åˆ©ç”¨å¯èƒ½ãªæ©Ÿèƒ½")
            st.markdown("""
            - **æœ€æ–°Responses API**: OpenAIã®æœ€æ–°API
            - **file_search ãƒ„ãƒ¼ãƒ«**: Vector Storeã‹ã‚‰ã®é«˜ç²¾åº¦æ¤œç´¢
            - **ãƒ•ã‚¡ã‚¤ãƒ«å¼•ç”¨**: æ¤œç´¢çµæœã®å‡ºå…¸è¡¨ç¤º
            - **ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºå¯èƒ½**: çµæœæ•°ã€ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ç­‰
            - **Agent SDKé€£æº**: ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            - **å‹å®‰å…¨å®Ÿè£…**: å‹ã‚¨ãƒ©ãƒ¼ä¿®æ­£æ¸ˆã¿
            - **ç’°å¢ƒå¤‰æ•°APIã‚­ãƒ¼**: ã‚»ã‚­ãƒ¥ã‚¢ãªè¨­å®šæ–¹æ³•
            """)

            # ç’°å¢ƒå¤‰æ•°ã®èª¬æ˜
            with st.expander("ğŸ”‘ APIã‚­ãƒ¼è¨­å®šã«ã¤ã„ã¦", expanded=False):
                st.markdown("""
                **ç’°å¢ƒå¤‰æ•°ã§ã®APIã‚­ãƒ¼è¨­å®š:**
                ```bash
                export OPENAI_API_KEY='your-api-key-here'
                ```
                
                **åˆ©ç‚¹:**
                - ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãŒå‘ä¸Š
                - secrets.toml ãƒ•ã‚¡ã‚¤ãƒ«ä¸è¦
                - æœ¬ç•ªç’°å¢ƒã§ã®æ¨™æº–çš„ãªæ–¹æ³•
                - ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã‹ã‚‰é™¤å¤–ã•ã‚Œã‚‹
                """)

            # å‹ã‚¨ãƒ©ãƒ¼è§£æ±ºã®èª¬æ˜
            with st.expander("ğŸ”§ å‹ã‚¨ãƒ©ãƒ¼ä¿®æ­£ã«ã¤ã„ã¦", expanded=False):
                st.markdown("""
                **ä¿®æ­£å†…å®¹:**
                - OpenAI SDKå‹å®šç¾©ã«å¯¾å¿œ
                - `# type: ignore[arg-type]` ã§å‹ãƒã‚§ãƒƒã‚¯å›é¿
                - å®Ÿéš›ã®APIå‹•ä½œã«ã¯å½±éŸ¿ãªã—
                - å‹å®‰å…¨ãªã‚³ãƒ¼ãƒ‰æ§‹é€ ã‚’ç¶­æŒ
                """)

            # ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°
            with st.expander("ğŸš¨ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°", expanded=False):
                st.markdown("""
                **APIã‚­ãƒ¼ã‚¨ãƒ©ãƒ¼ã®å ´åˆ:**
                ```bash
                # ç’°å¢ƒå¤‰æ•°ç¢ºèª
                echo $OPENAI_API_KEY
                
                # è¨­å®šæ–¹æ³•
                export OPENAI_API_KEY='your-api-key-here'
                
                # æ°¸ç¶šåŒ–ï¼ˆ.bashrc/.zshrcã«è¿½åŠ ï¼‰
                echo 'export OPENAI_API_KEY="your-api-key-here"' >> ~/.bashrc
                ```
                
                **ãã®ä»–ã®ã‚¨ãƒ©ãƒ¼:**
                - Vector Store IDãŒæ­£ã—ã„ã‹ç¢ºèª
                - OpenAI SDKãŒæœ€æ–°ç‰ˆã‹ç¢ºèª: `pip install --upgrade openai`
                - ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šã‚’ç¢ºèª
                """)

    # æ¤œç´¢å±¥æ­´ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    st.markdown("---")
    display_search_history()

    # ãƒ•ãƒƒã‚¿ãƒ¼
    st.markdown("---")
    st.markdown("#### æœ€æ–°RAGæ¤œç´¢ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆå®Œå…¨ä¿®æ­£ç‰ˆï¼‰**")
    st.markdown("ğŸš€ **OpenAI Responses API + file_search ãƒ„ãƒ¼ãƒ«** ã«ã‚ˆã‚‹æ¬¡ä¸–ä»£RAG")
    st.markdown("âœ¨ **æ–°æ©Ÿèƒ½**: æœ€æ–°APIå¯¾å¿œã€ãƒ•ã‚¡ã‚¤ãƒ«å¼•ç”¨ã€æ¤œç´¢ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã€å‹å®‰å…¨å®Ÿè£…")
    st.markdown("ğŸ”‘ **ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£**: ç’°å¢ƒå¤‰æ•°ã§ã®APIã‚­ãƒ¼ç®¡ç†")
    if AGENT_SDK_AVAILABLE:
        st.markdown("ğŸ”§ **Agent SDK**: ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†ã‚µãƒãƒ¼ãƒˆï¼ˆç°¡æ˜“ç‰ˆï¼‰")
    else:
        st.markdown("âš¡ **é«˜æ€§èƒ½**: ç›´æ¥Responses APIä½¿ç”¨")


if __name__ == "__main__":
    main()
